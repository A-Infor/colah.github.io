<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>colah's blog</title>
        <link>http://colah.github.io/</link>
        <description><![CDATA[]]></description>
        <atom:link href="http://colah.github.io/rss.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Mon, 08 Dec 2014 00:00:00 UTC</lastBuildDate>
        <item>
    <title>Groups and Group Convolutions</title>
    <link>http://colah.github.io/posts/2014-12-Groups-Convolution/</link>
    <description><![CDATA[
<script type="text/x-mathjax-config">
MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
  var TEX = MathJax.InputJax.TeX,
      MML = MathJax.ElementJax.mml;
  var CheckDimen = function (dimen) {
    if (dimen === "" ||
        dimen.match(/^\s*([-+]?(\.\d+|\d+(\.\d*)?))\s*(pt|em|ex|mu|px|mm|cm|in|pc)\s*$/))
            return dimen.replace(/ /g,"");
    TEX.Error("Bad dimension for image: "+dimen);
  };
  TEX.Definitions.macros.img = "myImage";
  TEX.Parse.Augment({
    myImage: function (name) {
      var src = this.GetArgument(name),
          valign = CheckDimen(this.GetArgument(name)),
          width  = CheckDimen(this.GetArgument(name)),
          height = CheckDimen(this.GetArgument(name));
      var def = {src:src};
      if (valign) {def.valign = valign}
      if (width)  {def.width  = width}
      if (valign) {def.height = height}
      this.Push(this.mmlToken(MML.mglyph().With(def)));
    }
  });
});
</script>

<script type="math/tex">\newcommand{sq}[1]{~\img{img/sqF-#1.png}{-0.2em}{1.1em}{1.1em}~}</script>
<script type="math/tex">\newcommand{cards}[1]{~\img{img/card-#1.png}{-0.6em}{2.0em}{2.0em}~}</script>


<!-- $\newcommand{sq}[1]{
  ~\raise{-1pt}{
    \style{height: 15px; content: url('img/sqF-#1.png')}{
      {~\over~}\over~
    }
  }~
}
\newcommand{cards}[1]{
  ~\raise{-4pt}{
    \style{height: 23px; content: url('img/card-#1.png')}{
      {{~~\over~~}\over{~~\over~~}}\over{~~\over~~}
    }
  }~~~
}
$ -->

<h1 id="symmetry">Symmetry</h1>
<p>Consider a square. Is it symmetric? How is it symmetric? How much symmetry does it have? What kind of symmetry does it have?</p>
<p>What do those questions even mean?</p>
<p>If you ask someone, they might tell you that a square has <em>rotational symmetry</em>. If you rotate a square by 90°, it’s the same shape. Without knowing which corner was which, it would seem the exact same as it was before. You could lift it up, rotate it, and set it back down so that it covers the exact same space.</p>
<p>Let’s call this rotation transformation <span class="math">\(r\)</span>. To be precise, <span class="math">\(r\)</span> rotates a square clockwise by 90°. For example, <span class="math">\(r\sq{e} = \sq{r}\)</span>. (The “F” on the square is there to let us determine orientation and see transformations.)</p>
<p>You might also be told that a square has <em>horizontal symmetry</em> or <em>vertical symmetry</em>. You can flip a square horizontally or vertically and still have a square. Let’s focus on horizontal symmetry for now. We’ll call horizontal flips <span class="math">\(s\)</span>. <span class="math">\(s\)</span> performs a reflection across a vertical line through the middle of the square. For example, <span class="math">\(s\sq{e} = \sq{s}\)</span>.</p>
<p>We now have two transformations, <span class="math">\(r\)</span> and <span class="math">\(s\)</span>, which transform squares into another square of the same shape. It turns out that these two transformations form a kind of “basis” for all the others. By using them in some pattern, you can build the other transformations, like vertical flipping.</p>
<p>Starting with our original square <span class="math">\(\sq{e}\)</span> in the bottom left corner, the following graph shows the transformed versions generated by combining <span class="math">\(r\)</span> and <span class="math">\(s\)</span> in different ways. <span class="math">\(r\)</span> and <span class="math">\(s\)</span> are represented by arrows of different colors. <span class="math">\(r\)</span> arrows are colored blue and <span class="math">\(s\)</span> arrows are colored red.</p>
<div class="bigcenterimgcontainer">
<img src="img/sqF-cayley.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>We can use the graph to investigate what happens if we perform a sequence of transformations. For example, what happens if we rotate, flip and then rotate again? Well, we start at our original square, <span class="math">\(\sq{e}\)</span>, and trace: <span class="math">\(\sq{e} \xrightarrow{r} \sq{r} \xrightarrow{s} \sq{r3s} \xrightarrow{r} \sq{s}\)</span>. In the end, we’re left with just horizontally flipped version of the original, <span class="math">\(s\sq{e} = \sq{s}\)</span>. If we want to express this surprising fact, we can use multiplication like notation: <span class="math">\(rsr \sq{e} = s \sq{e}\)</span>.</p>
<p>If we want to think about our graph a bit more abstractly, we can represent all the squares as the original square transformed by <span class="math">\(r\)</span> and <span class="math">\(s\)</span>. For example, <span class="math">\(\sq{r2s} = r^2s\sq{e}\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/sqF-cayley-factor.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Here, <span class="math">\(e\)</span> is the <em>identity transformation</em>, which doesn’t transform the object at all. For example <span class="math">\(e\sq{e} = \sq{e}\)</span>. (Why have <span class="math">\(e\)</span>, if it doesn’t do anything? It’s a lot like having the number zero.)</p>
<p>We can go a bit further. The original square, <span class="math">\(\sq{e}\)</span>, seems a bit unnecessary in <span class="math">\(rsr \sq{e} = s \sq{e}\)</span>. Why not just say <span class="math">\(rsr = s\)</span>? We can just drop the factored out <span class="math">\(\sq{e}\)</span>, both in equations and our graph.</p>
<div class="bigcenterimgcontainer">
<img src="img/sqF-cayley-symb.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Now, here’s the essential realization: <span class="math">\(r\)</span> and <span class="math">\(s\)</span> could have been other things and we would have had the exact same graph. <span class="math">\(r\)</span> could have been rotating 90° <em>counter</em>clockwise. <span class="math">\(s\)</span> could have been vertical flips. Or we could have been transforming an entirely different kind of object. All that matters is the relationship between <span class="math">\(r\)</span> and <span class="math">\(s\)</span>, how they interact. What we saw with the squares was just one particular way this graph, this abstract pattern, could appear in the real world.</p>
<p>Mathematicians call these abstract patterns <em>groups</em>. There is an entire field of math dedicated to them. Connections between a group and an object like the square are called <em>group actions</em>.</p>
<h1 id="but-what-is-a-group">But… What is a group?</h1>
<p>Not all graphs are groups. Only a very special kind of graph is. (We won’t give a formal definition here, but we will get a good feel for it.)</p>
<p>Firstly, the graph is directed (the edges are arrows) and has colored edges. At every vertex, exactly one arrow of a given color comes out and one goes in.</p>
<p>But the key property of these graphs is more subtle. We created our graph by starting with an original square, <span class="math">\(\sq{e}\)</span>. But what if we said the original square was <span class="math">\(\sq{s} = s\sq{e}\)</span>?</p>
<div class="bigcenterimgcontainer">
<img src="img/sqF-cayley-alt.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Which position we say is the “initial” position is arbitrary. No matter which position you think of as the initial one, the graph is the same. The graph is perfectly symmetrical, in some sense.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Imagine that the edges are paths of different color you can walk on, and you’re standing on one of the nodes: from your perspective the graph is the same no matter which node you’re standing on. No matter which node you’re on, taking a red path, a blue path, and then a red path and then a blue path again will bring you back to where you started.</p>
<p>In Euclidean space, we reason about points by their relative position to an origin. Similarly, in our group, we pick some origin (eg. <span class="math">\(\sq{e}\)</span>) and talk about points by their relative positions. We call these relative positions (such as <span class="math">\(r\)</span>, <span class="math">\(s\)</span>, or <span class="math">\(r^3s\)</span>), the <em>elements</em> of the group.</p>
<p>Just like we can add difference vectors of points, we can “add” elements of a group together. It isn’t <em>actually</em> addition, of course, but it is a natural way to combine elements of the group. Sometimes we talk about it by analogy with addition and write combining two elements <span class="math">\(a\)</span> and <span class="math">\(b\)</span> as <span class="math">\(a+b\)</span>, while other times we make analogies to multiplication and write <span class="math">\(a\cdot b\)</span>.</p>
<p>“Adding” or “multiplying” two group elements is actually quite similar to vector addition. We decide that one point on the graph is our identity element (the original position), and find the two elements we want to multiply, <span class="math">\(a\)</span> and <span class="math">\(b\)</span>. We pick paths from the identity to <span class="math">\(a\)</span> and <span class="math">\(b\)</span>. Then we stick the <span class="math">\(a\)</span> path on to the end of <span class="math">\(b\)</span>, to bring us to <span class="math">\(a+b\)</span> or <span class="math">\(a\cdot b\)</span> (depending on the chosen notation).</p>
<div class="bigcenterimgcontainer">
<img src="img/sqF-add.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<h1 id="the-algebraic-perspective">The Algebraic Perspective</h1>
<p><em>(This section is optional.)</em></p>
<p>The above is almost unrecognizable as group theory, from a traditional perspective. Usually, we think of groups as a kind of abstraction.</p>
<p>There are lots of kinds of mathematical objects and, as you look at more of them, one beings to see patterns. For example, in arithmetic, we see <span class="math">\(a\!\cdot\!(b+c) ~=~ a\!\cdot\! b ~+~ a\!\cdot\! c\)</span> and in set theory we see <span class="math">\(A\cap (B \cup C) = A\cap B ~\cup~ A\cap C\)</span>. There are many other examples of this pattern, and many other patterns.</p>
<p>One also notices that many important results are true for a broad class of objects, and they’re all true for the same reason. They’re true because all the objects observe a particular pattern. Knowing that a mathematical object obeys that pattern is sufficient to prove the result holds.</p>
<p>So, we formalize those patterns into what we call <em>mathematical structures</em>.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> There’s <strong>a lot</strong> of them, and you can find a <a href="http://en.wikipedia.org/wiki/List_of_algebraic_structures">very long list of algebraic ones on wikipedia</a>. We can study a mathematical structure and prove results that hold for any instance of that structure. (Programmers and computer scientists can see this as making mathematics polymorphic.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>)</p>
<p>We can now give the classical definition of a group. Don’t worry too much if you have trouble following.</p>
<p><strong>Definition:</strong> A group <span class="math">\(G = (S, ~\cdot~)\)</span> is a set <span class="math">\(S\)</span> equipped with a binary operation <span class="math">\((~\cdot~)\)</span>, a function mapping pairs of group elements to group elements, with the following properties:</p>
<ul>
<li>There exists an identity element, <span class="math">\(e \in S\)</span>, such that <span class="math">\(e\cdot x ~=~ x \cdot e ~=~ x\)</span> for all <span class="math">\(x \in S\)</span>.</li>
<li>For all elements <span class="math">\(x \in S\)</span>, there exists an inverse element <span class="math">\(x^{-1} \in S\)</span> such that <span class="math">\(x\cdot x^{-1} = x^{-1}\cdot x = e\)</span>.</li>
<li>The operation <span class="math">\((~\cdot~)\)</span> is associative. That is, <span class="math">\((a\cdot b)\cdot c ~=~ a\cdot (b\cdot c)\)</span> for all <span class="math">\(a,b,c \in S\)</span>,</li>
</ul>
<p>Why those rules? Why not more or less? Well, we could define a group to have more or less requirements. If it was weaker, had less requirements, more kinds of objects would be groups and the results we prove about groups would be more broadly applicable. If it was stronger, had more requirements, we would be talking about a more specific kind of object and could prove more about them. In mathematics one often balances generality and specificity like this.</p>
<p>Mathematicians study both weaker and stronger versions of groups. But, somehow, groups are special. They aren’t too hot, they aren’t too cold: they’re just right.</p>
<p>This might seem kind of arbitrary. Why should these particular rules be a particularly good collection? One thing that I find very helpful and motivating is realizing that they’re equivalent to the requirements we made when we were thinking of groups as graphs. Identity corresponds to there being a starting point, inverses to being able to go backwards on arrows, and associativity is equivalent to the perfect symmetry of the graph.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<h1 id="a-group-from-three-cards">A Group from Three Cards</h1>
<p>Consider three cards, <span class="math">\(\cards{123}\)</span>. There are some transformations that are natural to apply to them. We’ll call the operation of switching the first two cards <span class="math">\((12)\)</span>. Similarly, we’ll call the operation of switching the second cards <span class="math">\((23)\)</span>. So,</p>
<p><span class="math">\[(12)\cards{123} = \cards{213} ~~~~~~~~~~~~~~~~~~~~~~~~ (23)\cards{123} = \cards{132}\]</span></p>
<p>Together, these two operations generate a group, the <a href="http://en.wikipedia.org/wiki/Symmetric_group">Symmetric Group</a> on 3 symbols, <span class="math">\(S_3\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/card-cayley.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Each group element is a particular way to rearrange the cards, a permutation.</p>
<h1 id="shuffling-cards">Shuffling Cards</h1>
<p>One interesting thing to think about is shuffling. When we shuffle cards, we try to put them in a random ordering, a random permutation. This means we create a probability distribution over the group.</p>
<p>Ideally, our shuffle would give us a uniform distribution – every permutation would be equally likely. But we can easily imagine an imperfect shuffle, where some permutations are more likely than others.</p>
<div class="centerimgcontainer">
<img src="img/card-shuffle1.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Of course, if the first shuffle doesn’t randomize them, we can shuffle again!</p>
<div class="centerimgcontainer">
<img src="img/card-shuffle2.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Generally, repeated shuffles will cause probability mass to diffuse, bringing us closer to the uniform distribution.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
<p>This should feel similar to the falling ball example in the <a href="../2014-07-Understanding-Convolutions/">Understanding Convolutions post</a>. Fundamentally, they are the same thing: convolution.</p>
<div class="centerimgcontainer">
<img src="img/FallingBall.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<h1 id="group-convolutions">Group Convolutions</h1>
<p>The earlier visualizations of probability distributions on the permutations were kind of messy. The natural way to visualize it is on the Cayley diagram!</p>
<p>Let’s consider a very simple probability distribution. 40% of the time we apply the operation <span class="math">\((12)\)</span>, permuting our cards to <span class="math">\(\cards{213}\)</span>. 60% of the time we apply <span class="math">\((23)\)</span>, permuting our cards to <span class="math">\(\cards{132}\)</span>. That’s a terrible shuffle, but it is easy to think about.</p>
<div class="centerimgcontainer">
<img src="img/cayley-prob.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>To be a bit more explicit, let’s picture us as starting with all the probability density on the unpermuted cards <span class="math">\(\cards{123}\)</span> (i.e. the identity), and then we apply our very silly shuffle.</p>
<p>When we shuffle, we sample this distribution, getting some permutation <span class="math">\(a\)</span> with probability <span class="math">\(f(a)\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/card-conv1.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>What happens when we shuffle a second time?</p>
<p>Well, the first time we shuffled, we got a permutation <span class="math">\(a\)</span> with probability <span class="math">\(f(a)\)</span>. The second time we shuffle, we will get another permutation <span class="math">\(b\)</span> with probability <span class="math">\(g(b)\)</span>. These two actions happen with probability <span class="math">\(f(a)g(b)\)</span> and result is a permutation <span class="math">\(c = b\cdot a\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/card-conv-steps.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>To get the actual probability of <span class="math">\(c\)</span>, though, it is not sufficient to just look at one pair of permutations that bring us to <span class="math">\(c\)</span>. Instead, we need to sum over all possible pairs of permutations. This is the convolution of <span class="math">\(g\)</span> and <span class="math">\(f\)</span> (like in function composition, the right side goes first).</p>
<p><span class="math">\[(g\ast f)(c) = \sum_{b \cdot a = c} g(b)f(a)\]</span></p>
<p>Substituting <span class="math">\(a = b^{-1}c\)</span>, we get:</p>
<p><span class="math">\[(g\ast f)(c) = \sum_{a} g(a^{-1}c)f(a)\]</span></p>
<p>This can be nicely thought of as a sum over the intermediate permutations, <span class="math">\(a\)</span>, looking at the probability of that intermediate permutation, and the probability of the permutation necessary to bring us to <span class="math">\(c\)</span> from there.</p>
<div class="bigcenterimgcontainer">
<img src="img/card-conv2.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Alternatively, we can substitute <span class="math">\(a = b^{-1}c\)</span> to get:</p>
<p><span class="math">\[(g\ast f)(c) = \sum_{b} g(b)f(b^{-1}c)\]</span></p>
<p>The traditional definition of group convolution. (If you let the group operation be addition, this is the normal definition of convolution.)</p>
<h1 id="further-generalizations-of-convolution">Further Generalizations of Convolution</h1>
<p><em>(This section is optional and assumes a stronger background than the rest of the article. Less mathematically inclined readers might wish to skip this section.)</em></p>
<p>The traditional definition of convolution requires that you be able to take inverses, and multiply every element by every other element. This means you need to be working on a group, or perhaps a quasigroup.</p>
<p>But if you switch to the definition <span class="math">\((g\ast f)(c) = \sum_{b \cdot a = c} g(b)f(a)\)</span>, which seems much more natural, convolution makes sense on just about any algebraic structure with a binary operator. Certainly, you can talk about convolutions on monoids, groupoids, and categories. As far as I can tell, no one’s really considered these.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></p>
<p>One cute thing about this is that convolution often inherits the algebraic properties of the domains of the functions being convolved. For example, if you convolve functions on associative domains, the convolution operation is associative:</p>
<p><span class="math">\[((A\ast B) \ast C)(x) = \sum_{a \cdot b \cdot c = x} A(a)B(b)C(c) = (A\ast (B \ast C))(x)\]</span></p>
<p>Similarly, if the domain is commutative, so is convolution. And if it has identity, so does convolution. Sadly, convolution doesn’t get inverses if the domain has inverses, so the parallel breaks down at Abelian monoids.</p>
<p>With the math working out so nicely, you might wonder if there’s any reason one might actually use these. Well, convolution on monoids seems natural in cases where you “can’t go backwards”. And convolution on categories allows for a kind of state. In fact, I think you could very naturally describe probabilistic automaton in terms of category convolutions.</p>
<h1 id="conclusion">Conclusion</h1>
<p>This essay takes an unusual perspective on group theory. Cayley diagrams have been around for a long time, but, as far as I know, taking them seriously as an approach to group theory, as a kind of foundation, is a recent idea, engineered by Nathan Carter in his book <em>Visual Group Theory</em>. Interested readers are encouraged to look at his book.</p>
<p>Group convolutions provide elegant language for talking about lots of situations involving probability. But, since this is a series of blog posts on <em>convolutional neural networks</em>, you may suspect that I have other interests in them. Well, you guessed correctly. Group convolutions naturally extend convolutional neural networks, with everything fitting together extremely nicely. Since convolutional neural networks are one of the most powerful tools in machine learning right now, that’s pretty interesting. In our next post, we will explore these networks.</p>
<h1 id="next-posts-in-this-series">Next Posts in this Series</h1>
<p>This post is part of a series on convolutional neural networks and their generalizations. The first two posts will be review for those familiar with deep learning, while later ones should be of interest to everyone. To get updates, subscribe to my <a href="../../rss.xml">RSS feed</a>!</p>
<p>Please comment below or on the side. Pull requests can be made on <a href="https://github.com/colah/group-conv-post">github</a>.</p>
<h1 id="acknowledgements">Acknowledgements</h1>
<p>I’m grateful to Yomna Nasser, Harry de Valence, Sam Eisenstat, and Sebastian Zany for taking the time to read and comment on draft version of this post – their feedback improved it a lot!</p>
<p>I’m also grateful to Guillaume Alain, Eliana Lorch, Dario Amodei, Aaron Courville, Yoshua Bengio, and Michael Nielsen for discussion of group convolution and its potential applications to neural networks.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Note that the graph embedding isn’t necessarily symmetrical.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Usually people talk about <em>algebraic structures</em>, abstract mathematical structures from algebra. There are similar abstract mathematical structures in other areas, particularly in analysis. For example: <a href="http://en.wikipedia.org/wiki/Metric_space">metric spaces</a>, <a href="http://en.wikipedia.org/wiki/Topological_space">topological spaces</a> and <a href="http://en.wikipedia.org/wiki/Measure_(mathematics)">measure spaces</a>. However, these are rarely lumped together in the way that algebraic structures are.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>This is actually a very deep analogy. In programming, we often try to write polymorphic functions that can act on many kinds of objects. In mathematics, we’re trying to make polymorphic proofs that can operate on different kinds of mathematical object. The <a href="http://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">Curry–Howard correspondence</a> formalizes this connection between programs and proofs.</p>
<p>(Some programming languages, like Haskell, even have implementations of common algebraic structures as classes!)</p>
<p>It’s also worth noting that, just as most approaches to polymorphism in programming give us subclasses and superclasses, algebraic structures also kind of have “sub-structures” and “super-structures”.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>The associativity part is a bit tricky to see, especially because we never rigorously defined the “perfect symmetry” of our “group graphs.”</p>
<p>One definition is that, given a loop originating at <span class="math">\(e\)</span> on the graph, <span class="math">\(((bc)d)... = e\)</span>, that same sequence is also a loop if it starts at a point <span class="math">\(a\)</span>, that is <span class="math">\((((ab)c)d)... = a\)</span>. It’s pretty straightforward to see that this follows from associativity, but what about the other direction?</p>
<p>Well, we want to prove for all <span class="math">\(a,b,c\)</span>, that, <span class="math">\(a(bc) = (ab)c\)</span>. Let <span class="math">\(d = (bc)^{-1}\)</span>, the reverse of the path to <span class="math">\(bc\)</span>. Then <span class="math">\((bc)d = e\)</span> is a loop. By the graph symmetry, <span class="math">\(((ab)c)d = a\)</span>. We now right-mulitply by <span class="math">\(d^{-1} = (bc)\)</span> to get <span class="math">\((ab)c = a(bc)\)</span>, which is associativity.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>How many times do you have to shuffle a deck of cards to make it truly random? This question was explored by the mathematician Persi Diaconis.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>I can’t really find instances of people talking about these convolutions as independent things, but the operation seems to be implicitly constructed in objects built to study these structures. Just as multiplication in <a href="http://en.wikipedia.org/wiki/Group_ring">group rings</a> is group convolution, multiplication in <a href="http://en.wikipedia.org/wiki/Monoid_ring">monoid rings</a> is monoid convolution, multiplication in <a href="http://en.wikipedia.org/wiki/Groupoid_algebra">groupoid algebras</a> is groupoid convolution, and multiplication in <a href="http://en.wikipedia.org/wiki/Categorical_algebra">categorical algebras</a> is category convolution.<a href="#fnref6">↩</a></p></li>
</ol>
</section>]]></description>
    <pubDate>Mon, 08 Dec 2014 00:00:00 UT</pubDate>
    <guid>http://colah.github.io/posts/2014-12-Groups-Convolution/</guid>
</item>
<item>
    <title>Visualizing MNIST: An Exploration of Dimensionality Reduction</title>
    <link>http://colah.github.io/posts/2014-10-Visualizing-MNIST/</link>
    <description><![CDATA[<script src="js/foreign/d3.v3.min.js" charset="utf-8"></script>
<script src="js/foreign/jquery-1.7.0.min.js" charset="utf-8"></script>
<script src="js/foreign/jquery-ui.min.js" charset="utf-8"></script>
<script src="js/three.min.js"></script>
<script src="js/foreign/TrackballControls.js"></script>
<link rel="stylesheet" href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.10.3/themes/smoothness/jquery-ui.min.css">
<script src="js/BasicVis.js" type="text/javascript"></script>
<script src="js/MnistVis.js" type="text/javascript"></script>
<script src="js/data/MNIST.js" type="text/javascript"></script>
<script src="js/data/mnist_pca.js" type="text/javascript"></script>
<script src="js/data/MNIST-SNE-good.js"></script>
<!-- <script src="./data/WordEmbed-Vecs.js" type="text/javascript"></script> -->
<!--  <script src="./data/WordEmbed-Meta.js" type="text/javascript"></script> -->

<script type="text/x-mathjax-config">
MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
  var TEX = MathJax.InputJax.TeX,
      MML = MathJax.ElementJax.mml;
  var CheckDimen = function (dimen) {
    if (dimen === "" ||
        dimen.match(/^\s*([-+]?(\.\d+|\d+(\.\d*)?))\s*(pt|em|ex|mu|px|mm|cm|in|pc)\s*$/))
            return dimen.replace(/ /g,"");
    TEX.Error("Bad dimension for image: "+dimen);
  };
  TEX.Definitions.macros.img = "myImage";
  TEX.Parse.Augment({
    myImage: function (name) {
      var src = this.GetArgument(name),
          valign = CheckDimen(this.GetArgument(name)),
          width  = CheckDimen(this.GetArgument(name)),
          height = CheckDimen(this.GetArgument(name));
      var def = {src:src};
      if (valign) {def.valign = valign}
      if (width)  {def.width  = width}
      if (valign) {def.height = height}
      this.Push(this.mmlToken(MML.mglyph().With(def)));
    }
  });
});
</script>
<style>

  .hover_show {
    opacity: 0.0;
  }
  .hover_show:hover {
    opacity: 0.4;
  }

  .highlight {
    opacity: 0.8;
  }
  .highlight:hover {
    opacity: 1.0;
  }

  .figure {
    width: 100%;
    margin-top: 30px;
    margin-bottom: 20px;
  }

</style>

<script type="math/tex">\newcommand{mnist}[2][A]{\img{img/mnist/#1-#2.png}{-0.15em}{1em}{1em}}</script>


<script type="text/javascript">
function mult_img_display (div, data) {
  var N = 7;
  div.style('width', '100%');
  var W = parseInt(div.style('width'));
  div.style('height', W/N);
  div.style('position', 'relative');
  for (var n = 0; n < 4; n++) {
    var div2 = div.append('div')
      .style('position', 'absolute')
      .style('left', (n+(N-4)/2)*W/N);
    //  .style('position', 'absolute')
    //  .left(n*W/5);
    var img_display = new BasicVis.ImgDisplay(div2)
      .shape([28,28])
      .imgs(data)
      .show(n);
    img_display.canvas
      .style('border', '2px solid #000000')
      .style('width', W/N*0.85);
  }
}

var mnist_tooltip = new BasicVis.ImgTooltip();
mnist_tooltip.img_display.shape([28,28]);
mnist_tooltip.img_display.imgs(mnist_xs);
setTimeout(function() {mnist_tooltip.hide();}, 3000);
</script>

<p>At some fundamental level, no one understands machine learning.</p>
<p>It isn’t a matter of things being too complicated. Almost everything we do is fundamentally very simple. Unfortunately, an innate human handicap interferes with us understanding these simple things.</p>
<p>Humans evolved to reason fluidly about two and three dimensions. With some effort, we may think in four dimensions. Machine learning often demands we work with thousands of dimensions – or tens of thousands, or millions! Even very simple things become hard to understand when you do them in very high numbers of dimensions.</p>
<p>Reasoning directly about these high dimensional spaces is just short of hopeless.</p>
<p>As is often the case when humans can’t directly do something, we’ve built tools to help us. There is an entire, well-developed field, called dimensionality reduction, which explores techniques for translating high-dimensional data into lower dimensional data. Much work has also been done on the closely related subject of visualizing high dimensional data.</p>
<p>These techniques are the basic building blocks we will need if we wish to visualize machine learning, and deep learning specifically. My hope is that, through visualization and observing more directly what is actually happening, we can understand neural networks in a much deeper and more direct way.</p>
<p>And so, the first thing on our agenda is to familiarize ourselves with dimensionality reduction. To do that, we’re going to need a dataset to test these techniques on.</p>
<h1 id="mnist">MNIST</h1>
<p>MNIST is a simple computer vision dataset. It consists of 28x28 pixel images of handwritten digits, such as:</p>
<br>
<div id="mnist_image_examples">

</div>
<script type="text/javascript">
(function () {
  var div = d3.select("#mnist_image_examples");
  mult_img_display(div, mnist_xs)
})()
</script>
<p><br></p>
<p>Every MNIST data point, every image, can be thought of as an array of numbers describing how dark each pixel is. For example, we might think of <span class="math">\(\mnist[1]{1}\)</span> as something like:</p>
<br>
<script type="math/tex; mode=display">
\bbox[5px,border:2px solid black]{\img{img/mnist/1-1.png}{-5.6em}{12em}{12em}}
 ~~ \simeq
\left[ {\scriptscriptstyle \begin{array}{cccccccccccccccccccccccccccc}
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & \bbox[#A0A0A0,1pt]{.6} & \bbox[#909090,1pt]{.8} & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & \bbox[#959595,1pt]{.7} & \bbox[#808080,1pt]{1} & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & \bbox[#959595,1pt]{.7} & \bbox[#808080,1pt]{1} & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & \bbox[#A5A5A5,1pt]{.5} & \bbox[#808080,1pt]{1} & \bbox[#B0B0B0,1pt]{.4} & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \bbox[#808080,1pt]{1} & \bbox[#B0B0B0,1pt]{.4} & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \bbox[#808080,1pt]{1} & \bbox[#B0B0B0,1pt]{.4} & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \bbox[#808080,1pt]{1} & \bbox[#959595,1pt]{.7} & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \bbox[#808080,1pt]{1} & \bbox[#808080,1pt]{1} & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \bbox[#858585,1pt]{.9} & \bbox[#808080,1pt]{1} & \bbox[#E0E0E0,1pt]{.1} & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \bbox[#C0C0C0,1pt]{.3} & \bbox[#808080,1pt]{1} & \bbox[#E0E0E0,1pt]{.1} & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
\end{array} } \right]
</script>
<p><br></p>
<p>Since each image has 28 by 28 pixels, we get a 28x28 array. We can flatten each array into a <span class="math">\(28*28 = 784\)</span> dimensional vector. Each component of the vector is a value between zero and one describing the intensity of the pixel. Thus, we generally think of MNIST as being a collection of 784-dimensional vectors.</p>
<p>Not all vectors in this 784-dimensional space are MNIST digits. Typical points in this space are very different! To get a sense of what a typical point looks like, we can randomly pick a few points and examine them. In a random point – a random 28x28 image – each pixel is randomly black, white or some shade of gray. The result is that random points look like noise.</p>
<br>
<div id="random_image_examples">

</div>
<script type="text/javascript">
(function () {
  var div = d3.select("#random_image_examples");
  var data = new Float32Array(784*10);
  for (var n = 0; n < data.length; n++) {
    data[n] = Math.random();
  }
  mult_img_display(div, data)
})()
</script>
<p><br></p>
<p>Images like MNIST digits are very rare. While the MNIST data points are <em>embedded</em> in 784-dimensional space, they live in a very small subspace. With some slightly harder arguments, we can see that they occupy a lower dimensional subspace.</p>
<p>People have lots of theories about what sort of lower dimensional structure MNIST, and similar data, have. One popular theory among machine learning researchers is the <em>manifold hypothesis</em>: MNIST is a low dimensional manifold, sweeping and curving through its high-dimensional embedding space. Another hypothesis, more associated with topological data analysis, is that data like MNIST consists of blobs with tentacle-like protrusions sticking out into the surrounding space.</p>
<p>But no one really knows, so lets explore!</p>
<h1 id="the-mnist-cube">The MNIST Cube</h1>
<p>We can think of the MNIST data points as points suspended in a 784-dimensional cube. Each dimension of the cube corresponds to a particular pixel. The data points range from zero to one according to the pixels intensity. On one side of the dimension, there are images where that pixel is white. On the other side of the dimension, there are images where it is black. In between, there are images where it is gray.</p>
<br>
<div style="width:70%; position: relative; margin: 0 auto;">
<img src="./img/mnist_pca/MNIST-p1815-1.png" style="width: 22%; left:0%;"> <img src="./img/mnist_pca/MNIST-p1815-2.png" style="position: absolute; width: 22%; left:26%;"> <img src="./img/mnist_pca/MNIST-p1815-3.png" style="position: absolute; width: 22%; left:52%;"> <img src="./img/mnist_pca/MNIST-p1815-4.png" style="position: absolute; width: 22%; left:78%;"> <br>
<div style="border: 1px solid rgb(0, 0, 0); width: 100%; height: 10.4166666666667px; background: linear-gradient(to right, white, black);">

</div>
</div>
<p><br></p>
<p>If we think of it this way, a natural question occurs. What does the cube look like if we look at a particular two-dimensional face? Like staring into a snow-globe, we see the data points projected into two dimensions, with one dimension corresponding to the intensity of a particular pixel, and the other corresponding to the intensity of a second pixel. Examining this allows us to explore MNIST in a very raw way.</p>
<p><br> <em>In this visualization, each dot is an MNIST data point. The dots are colored based on which class of digit the data point belongs to. When your mouse hovers over a dot, the image for that data point is displayed on each axis. Each axis corresponds to the intensity of a particular pixel, as labeled and visualized as a blue dot in the small image beside it. By clicking on the image, you can change which pixel is displayed on that axis.</em></p>
<div id="raw_mnist" class="figure">

</div>
<script type="text/javascript">
  var raw_mnist = null;
  function raw_mnist_show(a,b) {
    raw_mnist.x.pixel_selector.value(a);
    raw_mnist.y.pixel_selector.value(b);
  }
  setTimeout(function(){
    raw_mnist = new RawExploreMNIST("#raw_mnist");
    raw_mnist.x.pixel_selector.value([7,13]);
    raw_mnist.y.pixel_selector.value([18,16]);
    raw_mnist.bindToWindowResize();
  }, 2000);
</script>

<p>Exploring this visualization, we can see some glimpses of the structure of MNIST. Looking at the <a href="#raw_mnist" onclick="raw_mnist_show([7,13], [18,16])">pixels <span class="math">\(p_{18,16}\)</span> and <span class="math">\(p_{7,12}\)</span></a>, we are able to separate a lot of zeros to the bottom right and a lot of nines to the top left. Looking at <a href="#raw_mnist" onclick="raw_mnist_show([5,7], [7,10])">pixels <span class="math">\(p_{5,6}\)</span> and <span class="math">\(p_{7,9}\)</span></a> we can see a lot of twos at the top right and threes at the bottom right.</p>
<p>Despite minor successes like these, one can’t really can’t understand MNIST this way. The small insights one gains feel very fragile and feel a lot like luck. The truth is, simply, that very little of MNIST’s structure is visible from these perspectives. You can’t understand images by looking at just two pixels at a time.</p>
<p>But there’s lots of other perspectives we could look at MNIST from! In these perspectives, instead of looking a face straight on, one looks at it from an angle.</p>
<p>The challenge is that we need to choose what perspective we want to use. What angle do we want to look at it from horizontally? What angle do we want to look at it from vertically? Thankfully, there’s a technique called <a href="http://en.wikipedia.org/wiki/Principal_component_analysis">Principal Components Analysis</a> (PCA) that will find the best possible angle for us. By this, we mean that PCA will find the angle that spreads out the points the most (captures the most variance possible).</p>
<p>But, what does it even mean to look at a 784-dimensional cube from an angle? Well, we need to decide which direction every axis of the cube should be tilted: to one side, to the other, or somewhere in between?</p>
<p>To be concrete, the following are pictures of the two angles PCA chooses. Red represents tilting a pixel’s dimension to one side, blue to the other.</p>
<br>
<div style="width:70%; position: relative; margin: 0 auto;">
<img src="./img/mnist_pca/MNIST-PCA1-1.png" style="width: 22%; left:0%; visibility: hidden;"> <img src="./img/mnist_pca/MNIST-PCA1.png" style="position: absolute; width: 22%; left:26%;"> <img src="./img/mnist_pca/MNIST-PCA2.png" style="position: absolute; width: 22%; left:52%;">
</div>
<p><br></p>
<p>If an MNIST digit primarily highlights red, it ends up on one side. If it highlights blue, it ends up on a different side. The first angle – the “first principal component” – will be our horizontal angle, pushing ones (which highlight lots of red and little blue) to the left and zeros (which highlight lots or blue and little red) to the right.</p>
<br>
<div style="width:70%; position: relative; margin: 0 auto;">
<img src="./img/mnist_pca/MNIST-PCA1-1.png" style="width: 22%; left:0%;"> <img src="./img/mnist_pca/MNIST-PCA1-2.png" style="position: absolute; width: 22%; left:26%;"> <img src="./img/mnist_pca/MNIST-PCA1-3.png" style="position: absolute; width: 22%; left:52%;"> <img src="./img/mnist_pca/MNIST-PCA1-4.png" style="position: absolute; width: 22%; left:78%;"> <br>
<div style="border: 1px solid rgb(0, 0, 0); width: 100%; height: 10.4166666666667px; background: linear-gradient(to right, red, #E3E3E3, blue);">

</div>
</div>
<p><br></p>
<!-- <br>
<div style = "width:70%; position: relative; margin: 0 auto;">
<img src="./img/mnist_pca/MNIST-PCA2-1.png" style="width: 22%; left:0%;">
<img src="./img/mnist_pca/MNIST-PCA2-2.png" style="position: absolute; width: 22%; left:26%;">
<img src="./img/mnist_pca/MNIST-PCA2-3.png" style="position: absolute; width: 22%; left:52%;">
<img src="./img/mnist_pca/MNIST-PCA2-4.png" style="position: absolute; width: 22%; left:78%;">
</div>
<br> -->

<p>Now that we know what the best horizontal and vertical angle are, we can try to look at the cube from that perspective.</p>
<p><br></p>
<p><em>This visualization is much like the one above, but now the axes are fixed to displaying the first and second ‘principal components,’ basically angles of looking at the data. In the image on each axis, blue and red are used to denote what the ‘tilt’ is for that pixel. Pixel intensity in blue regions pushes a data point to one side, pixel intensity in red regions pushes us to the other.</em></p>
<div id="pca_mnist" class="figure" style="margin-bottom:0px;">

</div>
<div class="caption" style="margin-bottom:10px;">
<strong>Visualizing MNIST with PCA</strong>
</div>
<script type="text/javascript">
  var raw_mnist = null;
  mnist_pca.W1 = mnist_pca.W.subarray(0, 784);
  mnist_pca.W2 = mnist_pca.W.subarray(784, 2*784);
  var mnist_pca_plot;
  setTimeout(function(){
    mnist_pca_plot = new DirExploreMNIST("#pca_mnist");
    mnist_pca_plot.plot.b0(mnist_pca.W1);
    mnist_pca_plot.plot.b1(mnist_pca.W2);
    mnist_pca_plot.plot.scatter.yrange([-4,6]);
    mnist_pca_plot.plot.scatter.xrange([-2,10]);
    setTimeout(function() {
      for (var i = 0; i < 28; i++) 
      for (var j = 0; j < 28; j++) {
        mnist_pca_plot.x.pixel_display.pixel_values[i][j] = 12*mnist_pca.W1[i+28*(28-j)];
        mnist_pca_plot.y.pixel_display.pixel_values[i][j] = 12*mnist_pca.W2[i+28*(28-j)];
      }
      mnist_pca_plot.x.pixel_display.render();
      mnist_pca_plot.y.pixel_display.render();
    }, 50);
  }, 2000);
</script>
<p><br></p>
<p>While much better than before, it’s still not terribly good. Unfortunately, even looking at the data from the best angle, MNIST data doesn’t line up nicely for us to look at. It’s a non-trivial high-dimensional structure, and these sorts of linear projections just aren’t going to cut it.</p>
<p>Thankfully, we have some powerful tools for dealing with datasets which are… uncooperative.</p>
<h1 id="optimization-based-dimensionality-reduction">Optimization-Based Dimensionality Reduction</h1>
<p>What would we consider a success? What would it mean to have the ‘perfect’ visualization of MNIST? What should our goal be?</p>
<p>One really nice property would be if the distances between points in our visualization were the same as the distances between points in the original space. If that was true, we’d be capturing the global geometry of the data.</p>
<p>Let’s be a bit more precise. For any two MNIST data points, <span class="math">\(x_i\)</span> and <span class="math">\(x_j\)</span>, there are two notions of distance between them. One is the distance between them in the original space<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> and one is the distance between them in our visualization. We will use <span class="math">\(d^*_{i,j}\)</span> to denote the distance between <span class="math">\(x_i\)</span> and <span class="math">\(x_j\)</span> in the original space and <span class="math">\(d_{i,j}\)</span> to denote the distance between <span class="math">\(x_i\)</span> and <span class="math">\(x_j\)</span> in our visualization. Now we can define a <em>cost</em>:</p>
<p><span class="math">\[C = \sum_{i\neq j} ~(d^{*}_{i,j} - d_{i,j})^2\]</span></p>
<p>This value describes how <em>bad</em> a visualization is. It basically says: “It’s bad for distances to not be the same. In fact, it’s quadratically bad.” If it’s high, it means that distances are dissimilar to the original space. If it’s small, it means they are similar. If it is zero, we have a ‘perfect’ embedding.</p>
<p>That sounds like an optimization problem! And deep learning researchers know what to do with those! We pick a random starting point and apply <a href="http://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>. <a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<br>
<div id="mds_mnist" class="figure" style="width: 60%; margin: 0 auto; margin-bottom: 8px;">

</div>
<div class="caption">
<strong>Visualizing MNIST with MDS</strong>
</div>
<br>
<script type="text/javascript">
  setTimeout(function(){
    var test = new GraphLayout("#mds_mnist", 35);
    test.scatter.size(3.3);
    var test_wrap = new AnimationWrapper(test);
    test_wrap.button.on("mousemove", function() { mnist_tooltip.hide(); d3.event.stopPropagation();});

    setTimeout(function() {
      test.scatter.xrange([-15,15]);
      test.scatter.yrange([-15,15]);
      mnist_tooltip.bind(test.scatter.points);
      mnist_tooltip.bind_move(test.scatter.s);
      test_wrap.layout();
    }, 50);

    var W = new Worker("js/CostLayout-worker.js");

    test_wrap.bindToWorker(W);

    W.postMessage({cmd: "init", xs: mnist_xs, N: test.sne.length/2, D: 784, cost: "MDS"});
    test_wrap.run   = function(){ W.postMessage({cmd: "run", steps: 700, skip: 2, Kstep: 8.0, Kmu: 0.8})};

  }, 500);
</script>

<p>This technique is called <a href="http://en.wikipedia.org/wiki/Multidimensional_scaling">multidimensional scaling</a> (or MDS). If you like, there’s a more physical description of what’s going on. First, we randomly position each point on a plane. Next we connect each pair of points with a spring with the length of the original distance, <span class="math">\(d^{*}_{i,j}\)</span>. Then we let the points move freely and allow physics to take its course!</p>
<p>We don’t reach a cost of zero, of course. Generally, high-dimensional structures can’t be embedded in two dimensions in a way that preserves distances perfectly. We’re demanding the impossible! But, even though we don’t get a perfect answer, we do improve a lot on the original random embedding, and come to a decent visualization. We can see the different classes begin to separate, especially the ones.</p>
<h2 id="sammons-mapping">Sammon’s Mapping</h2>
<p>Still, it seems like we should be able to do much better. Perhaps we should consider different cost functions? There’s a huge space of possibilities. To start, there’s a lot of variations on MDS. A common theme is cost functions emphasizing <em>local</em> structure as more important to maintain than global structure. A very simple example of this is <a href="http://en.wikipedia.org/wiki/Sammon_mapping">Sammon’s Mapping</a>, defined by the cost function:</p>
<p><span class="math">\[C = \sum_{i\neq j} \frac{(d^{*}_{i,j} - d_{i,j})^2}{d^{*}_{i,j}}\]</span></p>
<p>In Sammon’s mapping, we try harder to preserve the distances between nearby points than between those which are far apart. If two points are twice as close in the original space as two others, it is twice as important to maintain the distance between them.</p>
<br>
<div id="sammon_mnist" class="figure" style="width: 60%; margin: 0 auto; margin-bottom: 8px;">

</div>
<div class="caption">
<strong>Visualizing MNIST with Sammon’s Mapping</strong>
</div>
<br>
<script type="text/javascript">
  setTimeout(function(){
    var test = new GraphLayout("#sammon_mnist", 35);
    test.scatter.size(3.3);
    var test_wrap = new AnimationWrapper(test);
    test_wrap.button.on("mousemove", function() { mnist_tooltip.hide(); d3.event.stopPropagation();});

    setTimeout(function() {
      test.scatter.xrange([-15,15]);
      test.scatter.yrange([-15,15]);
      mnist_tooltip.bind(test.scatter.points);
      mnist_tooltip.bind_move(test.scatter.s);
      test_wrap.layout();
    }, 50);

    var W = new Worker("js/CostLayout-worker.js");

    test_wrap.bindToWorker(W);

    W.postMessage({cmd: "init", xs: mnist_xs, N: test.sne.length/2, D: 784, cost: "sammon"});
    test_wrap.run   = function(){ W.postMessage({cmd: "run", steps: 600, skip: 2, Kstep: 5.5, Kmu: 0.8})};

  }, 500);
</script>


<p>For MNIST, the result isn’t that different. The reason has to do with a rather unintuitive property regarding distances in high-dimensional data like MNIST. Let’s consider the distances between some MNIST digits. For example, the distance between the similar ones, <span class="math">\(\mnist{6}\)</span> and <span class="math">\(\mnist{8}\)</span>, is <span class="math">\[d(\mnist{6}, \mnist{8}) = 4.53\]</span> On the other hand, the difference between the very different data points, <span class="math">\(\mnist{4}\)</span> and <span class="math">\(\mnist{12}\)</span>, is <span class="math">\[d(\mnist{4}, \mnist{12}) = 12.0\]</span> less than three times <span class="math">\(d(\mnist{6}, \mnist{8})\)</span>!</p>
<p>Because there’s so many ways similar points can be slightly different, the average distance between similar points is quite high. Conversely, as you get further away from a point, the amount of volume within that distance increases to an extremely high power, and so you are likely to run into different kinds of points. The result is that, in pixel space, the difference in distances between ‘similar’ and ‘different’ points can be much less than we’d like, even in good cases.</p>
<h2 id="graph-based-visualization">Graph Based Visualization</h2>
<p>Perhaps, if local behavior is what we want our embedding to preserve, we should optimize for that more explicitly.</p>
<p>Consider a <a href="http://en.wikipedia.org/wiki/Nearest_neighbor_graph">nearest neighbor graph</a> of MNIST. For example, consider a graph <span class="math">\((V,E)\)</span> where the nodes are MNIST data points, and each point is connected to the three points that are closest to it in the original space.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> This graph is a simple way to encode local structure and forget about everything else.</p>
<p>Given such a graph, we can use standard graph layout algorithms to visualize MNIST. Here, we will use <a href="http://en.wikipedia.org/wiki/Force-directed_graph_drawing">force-directed graph drawing</a>: we pretend that all points are repelling charged particles, and that the edges are springs. This gives us a cost function:</p>
<p><span class="math">\[C~ = ~\sum_{i\neq j}\frac{1}{d_{i,j}} ~+~ \frac{1}{2}\sum_{(i,j) \in E} (d_{i,j} - d^{*}_{i,j})^2\]</span></p>
<p>Which we minimize.</p>
<br>
<div id="graph_mnist" class="figure" style="width: 60%; margin: 0 auto; margin-bottom: 8px;">

</div>
<div class="caption">
<strong>Visualizing MNIST as a Graph</strong>
</div>
<br>
<script type="text/javascript">
  setTimeout(function(){
    var test = new GraphLayout("#graph_mnist");
    test.scatter.size(3.1);
    var test_wrap = new AnimationWrapper(test);
    test_wrap.button.on("mousemove", function() { mnist_tooltip.hide(); d3.event.stopPropagation();});

    setTimeout(function() {
      test.scatter.xrange([-35,35]);
      test.scatter.yrange([-35,35]);
      mnist_tooltip.bind(test.scatter.points);
      mnist_tooltip.bind_move(test.scatter.s);
      test_wrap.layout();
    }, 50);

    var W = new Worker("js/CostLayout-worker.js");

    test_wrap.bindToWorker(W);

    W.postMessage({cmd: "init", xs: mnist_xs, N: test.sne.length/2, D: 784, cost: "graph"});
    test_wrap.run   = function(){ W.postMessage({cmd: "run", steps: 700, skip: 2, Kstep: 7.0, Kmu: 0.8})};

  }, 500);
</script>

<p>The graph discovers a lot of structure in MNIST. In particular, it seems to find the different MNIST classes. While they overlap, during the graph layout optimization we can see the clusters sliding over each other. They are unable to avoid overlapping when embedded on the plane due to connections between classes, but the cost function is at least <em>trying</em> to separate them.</p>
<p>One nice property of the graph visualization is that it explicitly shows us which points are connected to which other points. In earlier visualizations, if we see a point in a strange place, we are uncertain as to whether it’s just stuck there, or if it should actually be there. The graph structure avoids this. For example, if you look at the red cluster of zeros, you will see a single blue point, the six <span class="math">\(\mnist{494}\)</span>, among them. You can see from its neighbors that it is supposed to be there, and from looking at it you can see that it is, in fact, a very poorly written six that looks more like a zero.</p>
<div id="isomap_mnist" class="figure" style="width: 60%; margin: 0 auto; ">

</div>
<script type="text/javascript">
/*

Isomap TODO: Is it worth the hassal to include? Probably not, given its poor performance.

* Speed up path finding algorithm
* 

One interesting use of a graph, like the one above, is to estimate distance along the data manifold. If you believe the manifold hypothesis, that data lives on a low-dimensional manifold swirling through a high-dimensional space, you really want to avoid your notion of distance 'jumping' to faraway sections of the manifold that pass nearby.

This is what isomap does. For every two points, we consider the shortest path between them in the original space that consists only of steps on the graph. Then we apply MDS.
*/
/*
  setTimeout(function(){
    var test = new GraphLayout("#isomap_mnist");
    test.scatter.size(3.1);
    var test_wrap = new AnimationWrapper(test);
    test_wrap.button.on("mousemove", function() { mnist_tooltip.hide(); d3.event.stopPropagation();});

    setTimeout(function() {
      test.scatter.xrange([-15,15]);
      test.scatter.yrange([-15,15]);
      mnist_tooltip.bind(test.scatter.points);
      mnist_tooltip.bind_move(test.scatter.s);
      test_wrap.layout();
    }, 50);

    var W = new Worker("js/CostLayout-worker.js");

    test_wrap.bindToWorker(W);

    W.postMessage({cmd: "init", xs: mnist_xs, N: test.sne.length/2, D: 784, cost: "isomap"});
    test_wrap.run   = function(){ W.postMessage({cmd: "run", steps: 1000, skip: 2, Kstep: 15.0, Kmu: 0.7})};

  }, 500);
*/
</script>

<h2 id="t-distributed-stochastic-neighbor-embedding">t-Distributed Stochastic Neighbor Embedding</h2>
<p>The final technique I wish to introduce is the <a href="http://jmlr.csail.mit.edu/papers/volume9/vandermaaten08a/vandermaaten08a.pdf">t-Distributed Stochastic Neighbor Embedding</a> (t-SNE). This technique is extremely popular in the deep learning community. Unfortunately, t-SNE’s cost function involves some non-trivial mathematical machinery and requires some significant effort to understand.</p>
<p>But, roughly, what t-SNE tries to optimize for is preserving the <em>topology</em> of the data. For every point, it constructs a notion of which other points are it’s ‘neighbors,’ trying to make all points have the same number of neighbors. Then it tries to embed them so that those points all have the same number of neighbors.</p>
<p>In some ways, t-SNE is a lot like the graph based visualization. But instead of just having points be neighbors (if there’s an edge) or not neighbors (if there isn’t an edge), t-SNE has a continuous spectrum of having points be neighbors to different extents.</p>
<p>t-SNE is often very successful at revealing clusters and subclusters in data.</p>
<br>
<div id="tsne_mnist" class="figure" style="width: 60%; margin: 0 auto; margin-bottom: 8px;">

</div>
<div class="caption">
<strong>Visualizing MNIST with t-SNE</strong>
</div>
<br>
<script type="text/javascript">
  setTimeout(function(){
    var test = new GraphLayout("#tsne_mnist");
    test.scatter.size(3.1);
    var test_wrap = new AnimationWrapper(test);
    test_wrap.button.on("mousemove", function() { mnist_tooltip.hide(); d3.event.stopPropagation();});

    setTimeout(function() {
      test.scatter.xrange([-35,35]);
      test.scatter.yrange([-35,35]);
      mnist_tooltip.bind(test.scatter.points);
      mnist_tooltip.bind_move(test.scatter.s);
      test_wrap.layout();
    }, 50);

    var W = new Worker("js/CostLayout-worker.js");

    test_wrap.bindToWorker(W);

    W.postMessage({cmd: "init", xs: mnist_xs, N: test.sne.length/2, D: 784, cost: "tSNE", perplexity:40});
    test_wrap.run   = function(){ W.postMessage({cmd: "run", steps: 1600, skip: 2, Kstep: 18.0, Kmu: 0.85})};

  }, 500);
</script>

<p>t-SNE does an impressive job finding clusters and subclusters in the data, but is prone to getting stuck in local minima. For example, in the following image we can see two clusters of zeros (red) that fail to come together because a cluster of sixes (blue) get stuck between them.</p>
<br>
<div style="width:35%; position: relative; margin: 0 auto;">
<img src="./img/tsne-localmin-1.png" style="width: 100%">
</div>
<p><br></p>
<p>A number of tricks can help us avoid these bad local minima. Firstly, using more data helps a lot. Because these visualizations are embeded in a blog post, they only use 1,000 points. Using the full 50,000 MNIST points works a lot better. In addition, it is recommended that one use <a href="http://en.wikipedia.org/wiki/Simulated_annealing">simulated annealing</a> and carefully select a number of hyperparamters.</p>
<p>Well done t-SNE plots reveal many interesting features of MNIST.</p>
<br>
<div id="tsne_mnist_nice" class="figure" style="width: 60%; margin: 0 auto; margin-bottom: 8px;">

</div>
<div class="caption">
<strong>A t-SNE plot of MNIST</strong>
</div>
<br>
<script type="text/javascript">
  setTimeout(function(){

    var sne = mnist_sne;

    var scatter = new BasicVis.ScatterPlot("#tsne_mnist_nice");
    scatter
      .N(mnist_sne.length/2)
      .xrange.fit(mnist_sne)
      .yrange.fit(mnist_sne)
      .x(function(i) {return mnist_sne[2*i  ];})
      .y(function(i) {return mnist_sne[2*i+1];})
      .size(3.1)
      .color(function(i){return d3.hsl(360*mnist_ys[i]/10.0,0.5,0.5);})
      //.enable_zoom()
      .bindToWindowResize();
    //scatter.s.style("border", "1px black solid");

    setTimeout(function() {
      scatter.xrange.fit(mnist_sne)
             .yrange.fit(mnist_sne);
      scatter.layout();
      mnist_tooltip.bind(scatter.points);
      mnist_tooltip.bind_move(scatter.s);
    }, 50);

  }, 500);
</script>

<p>An even nicer plot can be found on the page labeled 2590, in the original t-SNE paper, <a href="http://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf">Maaten &amp; Hinton (2008)</a>.</p>
<p>It’s not just the classes that t-SNE finds. Let’s look more closely at the ones.</p>
<br>
<div id="tsne_mnist_nice_ones" class="figure" style="width: 60%; margin: 0 auto; margin-bottom: 8px;">

</div>
<div class="caption">
<strong>A t-SNE plot of MNIST ones</strong>
</div>
<br>
<script type="text/javascript">
  setTimeout(function(){

    var sne = mnist_sne;

    var scatter = new BasicVis.ScatterPlot("#tsne_mnist_nice_ones");
    scatter
      .N(mnist_sne.length/2)
      .xrange.fit(mnist_sne)
      .yrange.fit(mnist_sne)
      .x(function(i) {return mnist_sne[2*i  ];})
      .y(function(i) {return mnist_sne[2*i+1];})
      .size(3.1)
      .color(function(i){
        if (mnist_ys[i] == 1) {
         return d3.hsl(360*mnist_ys[i]/10.0,0.5,0.5);
        } else {
         return d3.hsl(360*mnist_ys[i]/10.0,0.3,0.85);
        }
      })
      //.enable_zoom()
      .bindToWindowResize();
    //scatter.s.style("border", "1px black solid");

    setTimeout(function() {
      scatter.xrange.fit(mnist_sne)
             .yrange.fit(mnist_sne);
      scatter.layout();
      mnist_tooltip.bind(scatter.points, function(i) {return mnist_ys[i] == 1;});
      mnist_tooltip.bind_move(scatter.s);
    }, 50);

  }, 500);
</script>

<p>The ones cluster is stretched horizontally. As we look at digits from left to right, we see a consistent pattern.</p>
<p><span class="math">\[\mnist[1]{7} \to \mnist[1]{4} \to \mnist[1]{8} \to \mnist[1]{6} \to \mnist[1]{2} \to \mnist[1]{1}\]</span></p>
<p>They move from forward leaning ones, like <span class="math">\(\mnist[1]{4}\)</span>, into straighter like <span class="math">\(\mnist[1]{6}\)</span>, and finally to slightly backwards leaning ones, like <span class="math">\(\mnist[1]{1}\)</span>. It seems that in MNIST, the primary factor of variation in the ones is tilting. This is likely because MNIST normalizes digits in a number of ways, centering and scaling them. After that, the easiest way to be “far apart” is to rotate and not overlap very much.</p>
<p>Similar structure can be observed in other classes, if you look at the <a href="#tsne_mnist_nice">t-SNE plot</a> again.</p>
<h1 id="visualization-in-three-dimensions">Visualization in Three Dimensions</h1>
<p>Watching these visualizations, there’s sometimes this sense that they’re begging for another dimension. For example, watching the graph visualization optimize, one can see clusters slide over top of each other.</p>
<p>Really, we’re trying to compress this extremely high-dimensional structure into two dimensions. It seems natural to think that there would be very big wins from adding an additional dimension. If nothing else, at least in three dimensions a line connecting two clusters doesn’t divide the plane, precluding other connections between clusters.</p>
<p>In the following visualization, we construct a nearest neighbor graph of MNIST, as before, and optimize the same cost function. The only difference is that there are now three dimensions to lay it out in.</p>
<br>
<div class="figure" style="width: 90%; margin: 0 auto; border: 1px solid black; padding: 5px; margin-bottom: 8px;">
<div id="graph_mnist_3D" style="width: 100%">

</div>
</div>
<div class="caption">
<strong>Visualizing MNIST as a Graph in 3D</strong> <br> (click and drag to rotate)
</div>
<br>
<script type="text/javascript">
  setTimeout(function(){
    var test = new BasicVis.GraphPlot3("#graph_mnist_3D");
    test.controls.reset();
    test.layout();
    test._animate();
    test.point_classes = mnist_ys;

    var test_wrap = new AnimationWrapper(test);
    test_wrap.button.on("mousemove", function() { mnist_tooltip.hide(); d3.event.stopPropagation();});

    var tooltip = null;
    setTimeout(function() {
      test_wrap.layout();
      test.point_event_funcs["mouseover"] = function(i) {
        mnist_tooltip.display(i);
        mnist_tooltip.unhide();
      };
      test.point_event_funcs["mouseout"] = function(i) {
        mnist_tooltip.hide();
      };
      mnist_tooltip.bind_move(test.s);
      
    }, 50);

    var W = new Worker("js/CostLayout-worker-3D.js");
    W.onmessage = function(e) {
      data = e.data;
      switch (data.msg) {
        case "edges":
          test.make_points(1000);
          test.make_edges(data.edges);
          break;
        case "update":
          test.position(data.embed);
          break;
        case "done":
          test_wrap.on_done();
          break;
      }
    };

    W.postMessage({cmd: "init", xs: mnist_xs, N: 1000, D: 784, cost: "graph"});

    test_wrap.run   = function(){ W.postMessage({cmd: "run", steps: 300, skip: 1,  Kstep: 8.0, Kmu: 0.8})};
    test_wrap.reset = function(){ W.postMessage({cmd: "reset"})};

  }, 500);
</script>

<p>The three dimensional version, unsurprisingly, works much better. The clusters are quite separated and, while entangled, no longer overlap.</p>
<p>In this visualization, we can begin to see why it is easy to achieve around 95% accuracy classifying MNIST digits, but quickly becomes harder after that. You can make a lot of ground classifying digits by chopping off the colored protrusions above, the clusters of each class sticking out. (This is more or less what a linear Support Vector Machine does.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>) But there’s some much harder entangled sections, especially in the middle, that are difficult to classify.</p>
<p>Of course, we could do any of the above techniques in 3D! Even something as simple as MDS is able to display quite a bit in 3D.</p>
<br>
<div class="figure" style="width: 90%; margin: 0 auto; border: 1px solid black; padding: 5px; margin-bottom: 8px;">
<div id="MDS_mnist_3D" style="width: 100%">

</div>
</div>
<div class="caption">
<strong>Visualizing MNIST with MDS in 3D</strong> <br> (click and drag to rotate)
</div>
<br>
<script type="text/javascript">
  setTimeout(function(){
    var test = new BasicVis.GraphPlot3("#MDS_mnist_3D", 200);
    test.controls.reset();
    test.layout();
    test._animate();
    test.point_classes = mnist_ys;

    var test_wrap = new AnimationWrapper(test);
    test_wrap.button.on("mousemove", function() { mnist_tooltip.hide(); d3.event.stopPropagation();});

    var tooltip = null;
    setTimeout(function() {
      test_wrap.layout();
      test.point_event_funcs["mouseover"] = function(i) {
        mnist_tooltip.display(i);
        mnist_tooltip.unhide();
      };
      test.point_event_funcs["mouseout"] = function(i) {
        mnist_tooltip.hide();
      };
      mnist_tooltip.bind_move(test.s);
      
    }, 50);

    var W = new Worker("js/CostLayout-worker-3D.js");
    W.onmessage = function(e) {
      data = e.data;
      switch (data.msg) {
        case "edges":
          test.make_points(1000);
          test.make_edges(data.edges);
          break;
        case "update":
          test.position(data.embed);
          break;
        case "done":
          test_wrap.on_done();
          break;
      }
    };

    W.postMessage({cmd: "init", xs: mnist_xs, N: 1000, D: 784, cost: "MDS"});

    test_wrap.run   = function(){ W.postMessage({cmd: "run", steps: 300, skip: 1,  Kstep: 6.0, Kmu: 0.8})};
    test_wrap.reset = function(){ W.postMessage({cmd: "reset"})};

  }, 500);
</script>

<p>In three dimensions, MDS does a much better job separating the classes than it did with two dimensions.</p>
<p>And, of course, we can do t-SNE in three dimensions.</p>
<br>
<div class="figure" style="width: 90%; margin: 0 auto; border: 1px solid black; padding: 5px; margin-bottom: 8px;">
<div id="tsne_mnist_3D" style="width: 100%">

</div>
</div>
<div class="caption">
<strong>Visualizing MNIST with t-SNE in 3D</strong> <br> (click and drag to rotate)
</div>
<br>
<script type="text/javascript">
  setTimeout(function(){
    var test = new BasicVis.GraphPlot3("#tsne_mnist_3D", 400);
    test.controls.reset();
    test.layout();
    test._animate();
    test.point_classes = mnist_ys;

    var test_wrap = new AnimationWrapper(test);
    test_wrap.button.on("mousemove", function() { mnist_tooltip.hide(); d3.event.stopPropagation();});

    var tooltip = null;
    setTimeout(function() {
      test_wrap.layout();
      test.point_event_funcs["mouseover"] = function(i) {
        mnist_tooltip.display(i);
        mnist_tooltip.unhide();
      };
      test.point_event_funcs["mouseout"] = function(i) {
        mnist_tooltip.hide();
      };
      mnist_tooltip.bind_move(test.s);
      
    }, 50);

    var W = new Worker("js/CostLayout-worker-3D.js");
    W.onmessage = function(e) {
      data = e.data;
      switch (data.msg) {
        case "edges":
          test.make_points(1000);
          test.make_edges(data.edges);
          break;
        case "update":
          test.position(data.embed);
          break;
        case "done":
          test_wrap.on_done();
          break;
      }
    };

    W.postMessage({cmd: "init", xs: mnist_xs, N: 1000, D: 784, cost: "tSNE"});

    test_wrap.run   = function(){ W.postMessage({cmd: "run", steps: 500, skip: 1,  Kstep: 10.0, Kmu: 0.85})};
    test_wrap.reset = function(){ W.postMessage({cmd: "reset"})};

  }, 500);
</script>

<p>Because t-SNE puts so much space between clusters, it benefits a lot less from the transition to three dimensions. It’s still quite nice, though, and becomes much more so with more points.</p>
<p>If you want to visualize high dimensional data, there are, indeed, significant gains to doing it in three dimensions over two.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Dimensionality reduction is a well developed area, and we’re only scratching the surface here. There are hundreds of techniques and variants that are unmentioned here. I encourage you to explore!</p>
<p>It’s easy to slip into a mind set of thinking one of these techniques is better than the others, but I think they’re all complementary. There’s no way to map high-dimensional data into low dimensions and preserve all the structure. So, an approach must make trade offs, sacrificing one property to preserve another. PCA tries to preserve linear structure, MDS tries to preserve global geometry, and t-SNE tries to preserve topology (neighborhood structure).</p>
<p>These techniques give us a way to gain traction on understanding high-dimensional data. While directly trying to understand high-dimensional data with the human mind is all but hopeless, with these tools we can begin to make progress.</p>
<p>In the next post, we will explore applying these techniques to some different kinds of data – in particular, to visualizing representations of text. Then, equipped with these techniques, we will shift our focus to understanding neural networks themselves, visualizing how they transform high-dimensional data and building techniques to visualize the space of neural networks. If you’re interested, you can subscribe to my <a href="../../rss.xml">rss feed</a> so that you’ll see these posts when they are published.</p>
<p><em>(I would be delighted to hear your comments and thoughts: you can comment inline or at the end. For typos, technical errors, or clarifications you would like to see added, you are encouraged to make a pull request on <a href="https://github.com/colah/Visualizing-Deep-Learning/">github</a>)</em></p>
<h1 id="acknowledgements">Acknowledgements</h1>
<p>I’m grateful for the hospitality of Google’s deep learning research group, which had me as an intern while I wrote this post and did the work it is based on. I’m especially grateful to my internship host, Jeff Dean.</p>
<p>I was greatly helped by the comments, advice, and encouragement of many Googlers, both in the deep learning group and outside of it. These include: Greg Corrado, Jon Shlens, Matthieu Devin, Andrew Dai, Quoc Le, Anelia Angelova, Oriol Vinyals, Ilya Sutskever, Ian Goodfellow, Jutta Degener, and Anna Goldie.</p>
<p>I was strongly influenced by the thoughts, comments and notes of Michael Nielsen, especially his notes on Bret Victor’s work. Michael’s thoughts persuaded me that I should think seriously about interactive visualizations for understanding deep learning.</p>
<p>I was also helped by the support of a number of non-Googler friends, including Yoshua Bengio, Dario Amodei, Eliana Lorch, Taren Stinebrickner-Kauffman, and Laura Ball.</p>
<p>This blog post was made possible by a number of wonderful Javascript libraries, including <a href="http://d3js.org/">D3.js</a>, <a href="http://www.mathjax.org/">MathJax</a>, <a href="http://jquery.com/">jQuery</a>, and <a href="http://threejs.org/">three.js</a>. A big thank you to everyone who contributed to these libraries.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>We have a number of options for defining distance between these high-dimensional vectors. For this post, we will use L2 distance, <span class="math">\(d(x_i,x_j) = \sqrt{\sum_n (x_{i,n}-x_{j,n})^2}\)</span>  <a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>We initialize the points’ positions by sampling a Gaussian around the origin. Our optimization process isn’t standard gradient descent. Instead, we use a variant of momentum gradient descent. Before adding the gradient to the momentum, we normalize the gradient. This reduces the need for hyper-parameter tuning.  <a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Note that points can end up connected to more, if they are the nearest neighbor of many points.  <a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>This isn’t quite true. A linear SVM operates on the original space. This is a non-linear transformation of the original space. That said, this strongly suggests something similar in the original space, and so we’d expect something similar to be true.  <a href="#fnref4">↩</a></p></li>
</ol>
</section>]]></description>
    <pubDate>Thu, 09 Oct 2014 00:00:00 UT</pubDate>
    <guid>http://colah.github.io/posts/2014-10-Visualizing-MNIST/</guid>
</item>
<item>
    <title>Understanding Convolutions</title>
    <link>http://colah.github.io/posts/2014-07-Understanding-Convolutions/</link>
    <description><![CDATA[<p>In a <a href="../2014-07-Conv-Nets-Modular/">previous post</a>, we built up an understanding of convolutional neural networks, without referring to any significant mathematics. To go further, however, we need to understand convolutions.</p>
<p>If we just wanted to understand convolutional neural networks, it might suffice to roughly understand convolutions. But the aim of this series is to bring us to the frontier of convolutional neural networks and explore new options. To do that, we’re going to need to understand convolutions very deeply.</p>
<p>Thankfully, with a few examples, convolution becomes quite a straightforward idea.</p>
<h1 id="lessons-from-a-dropped-ball">Lessons from a Dropped Ball</h1>
<p>Imagine we drop a ball from some height onto the ground, where it only has one dimension of motion. <em>How likely is it that a ball will go a distance <span class="math">\(c\)</span> if you drop it and then drop it again from above the point at which it landed?</em></p>
<p>Let’s break this down. After the first drop, it will land <span class="math">\(a\)</span> units away from the starting point with probability <span class="math">\(f(a)\)</span>, where <span class="math">\(f\)</span> is the probability distribution.</p>
<p>Now after this first drop, we pick the ball up and drop it from another height above the point where it first landed. The probability of the ball rolling <span class="math">\(b\)</span> units away from the new starting point is <span class="math">\(g(b)\)</span>, where <span class="math">\(g\)</span> may be a different probability distribution if it’s dropped from a different height.</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-fagb.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>If we fix the result of the first drop so we know the ball went distance <span class="math">\(a\)</span>, for the ball to go a total distance <span class="math">\(c\)</span>, the distance traveled in the second drop is also fixed at <span class="math">\(b\)</span>, where <span class="math">\(a+b=c\)</span>. So the probability of this happening is simply <span class="math">\(f(a) \cdot g(b)\)</span>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>Let’s think about this with a specific discrete example. We want the total distance <span class="math">\(c\)</span> to be 3. If the first time it rolls, <span class="math">\(a=2\)</span>, the second time it must roll <span class="math">\(b=1\)</span> in order to reach our total distance <span class="math">\(a+b=3\)</span>. The probability of this is <span class="math">\(f(2) \cdot g(1)\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-split-21.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>However, this isn’t the only way we could get to a total distance of 3. The ball could roll 1 units the first time, and 2 the second. Or 0 units the first time and all 3 the second. It could go any <span class="math">\(a\)</span> and <span class="math">\(b\)</span>, as long as they add to 3.</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-splits-12-03.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>The probabilities are <span class="math">\(f(1) \cdot g(2)\)</span> and <span class="math">\(f(0) \cdot g(3)\)</span>, respectively.</p>
<p>In order to find the <em>total likelihood</em> of the ball reaching a total distance of <span class="math">\(c\)</span>, we can’t consider only one possible way of reaching <span class="math">\(c\)</span>. Instead, we consider <em>all the possible ways</em> of partitioning <span class="math">\(c\)</span> into two drops <span class="math">\(a\)</span> and <span class="math">\(b\)</span> and sum over the <em>probability of each way</em>.</p>
<p><span class="math">\[...~~ f(0)\!\cdot\! g(3) ~+~ f(1)\!\cdot\! g(2) ~+~ f(2)\!\cdot\! g(1)~~...\]</span></p>
<p>We already know that the probability for each case of <span class="math">\(a+b=c\)</span> is simply <span class="math">\(f(a) \cdot g(b)\)</span>. So, summing over every solution to <span class="math">\(a+b=c\)</span>, we can denote the total likelihood as:</p>
<p><span class="math">\[\sum_{a+b=c} f(a) \cdot g(b)\]</span></p>
<p>Turns out, we’re doing a convolution! In particular, the convolution of <span class="math">\(f\)</span> and <span class="math">\(g\)</span>, evaluated at <span class="math">\(c\)</span> is defined:</p>
<p><span class="math">\[(f\ast g)(c) = \sum_{a+b=c} f(a) \cdot g(b)~~~~\]</span></p>
<p>If we substitute <span class="math">\(b = c-a\)</span>, we get:</p>
<p><span class="math">\[(f\ast g)(c) = \sum_a f(a) \cdot g(c-a)\]</span></p>
<p>This is the standard definition<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> of convolution.</p>
<p>To make this a bit more concrete, we can think about this in terms of positions the ball might land. After the first drop, it will land at an intermediate position <span class="math">\(a\)</span> with probability <span class="math">\(f(a)\)</span>. If it lands at <span class="math">\(a\)</span>, it has probability <span class="math">\(g(c-a)\)</span> of landing at a position <span class="math">\(c\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-OnePath.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>To get the convolution, we consider all intermediate positions.</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-SumPaths.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<h1 id="visualizing-convolutions">Visualizing Convolutions</h1>
<p>There’s a very nice trick that helps one think about convolutions more easily.</p>
<p>First, an observation. Suppose the probability that a ball lands a certain distance <span class="math">\(x\)</span> from where it started is <span class="math">\(f(x)\)</span>. Then, afterwards, the probability given that it started a distance <span class="math">\(x\)</span> from where it landed is <span class="math">\(f(-x)\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-Reverse.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>If we know the ball lands at a position <span class="math">\(c\)</span> after the second drop, what is the probability that the previous position was <span class="math">\(a\)</span>?</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-BackProb.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>So the probability that the previous position was <span class="math">\(a\)</span> is <span class="math">\(g(-(a-c)) = g(c-a)\)</span>.</p>
<p>Now, consider the probability each intermediate position contributes to the ball finally landing at <span class="math">\(c\)</span>. We know the probability of the first drop putting the ball into the intermediate position a is <span class="math">\(f(a)\)</span>. We also know that the probability of it having been in <span class="math">\(a\)</span>, if it lands at <span class="math">\(c\)</span> is <span class="math">\(g(c-a)\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-Intermediate.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Summing over the <span class="math">\(a\)</span>s, we get the convolution.</p>
<p>The advantage of this approach is that it allows us to visualize the evaluation of a convolution at a value <span class="math">\(c\)</span> in a single picture. By shifting the bottom half shifting around, we can evaluate the convolution at other values of <span class="math">\(c\)</span>. This allows us to understand the convolution as a whole.</p>
<p>For example, we can see that it peaks when the distributions align.</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-Intermediate-Align.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>And shrinks as the intersection between the distributions gets smaller.</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-Intermediate-Sep.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>By using this trick in an animation, it really becomes possible to visually understand convolutions.</p>
<p>Below, we’re able to visualize the convolution of two box functions:</p>
<div class="bigcenterimgcontainer">
<img src="img/Wiki-BoxConvAnim.gif" alt="" style="">
<div class="caption">
From Wikipedia
</div>
</div>
<div class="spaceafterimg">

</div>
<p>Armed with this perspective, a lot of things become more intuitive.</p>
<p>Let’s consider a non-probabilistic example. Convolutions are sometimes used in audio manipulation. For example, one might use a function with two spikes in it, but zero everywhere else, to create an echo. As our double-spiked function slides, one spike hits a point in time first, adding that signal to the output sound, and later, another spike follows, adding a second, delayed copy.</p>
<h1 id="higher-dimensional-convolutions">Higher Dimensional Convolutions</h1>
<p>Convolutions are an extremely general idea. We can also use them in a higher number of dimensions.</p>
<p>Let’s consider our example of a falling ball again. Now, as it falls, it’s position shifts not only in one dimension, but in two.</p>
<div class="bigcenterimgcontainer">
<img src="img/ProbConv-TwoDim.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Convolution is the same as before:</p>
<p><span class="math">\[(f\ast g)(c) = \sum_{a+b=c} f(a) \cdot g(b)\]</span></p>
<p>Except, now <span class="math">\(a\)</span>, <span class="math">\(b\)</span> and <span class="math">\(c\)</span> are vectors. To be more explicit,</p>
<p><span class="math">\[(f\ast g)(c_1, c_2) = \sum_{\begin{array}{c}a_1+b_1=c_1\\a_2+b_2=c_2\end{array}} f(a_1,a_2) \cdot g(b_1,b_2)\]</span></p>
<p>Or in the standard definition:</p>
<p><span class="math">\[(f\ast g)(c_1, c_2) = \sum_{a_1, a_2} f(a_1, a_2) \cdot g(c_1-a_1,~ c_2-a_2)\]</span></p>
<p>Just like one-dimensional convolutions, we can think of a two-dimensional convolution as sliding one function on top of another, multiplying and adding.</p>
<p>One common application of this is image processing. We can think of images as two-dimensional functions. Many important image transformations are convolutions where you convolve the image function with a very small, local function called a “kernel.”</p>
<div class="centerimgcontainer">
<img src="img/RiverTrain-ImageConvDiagram.png" alt="" style="">
<div class="caption">
From the <a href="http://rivertrail.github.io/RiverTrail/tutorial/">River Trail documentation</a>
</div>
</div>
<div class="spaceafterimg">

</div>
<p>The kernel slides to every position of the image and computes a new pixel as a weighted sum of the pixels it floats over.</p>
<p>For example, by averaging a 3x3 box of pixels, we can blur an image. To do this, our kernel takes the value <span class="math">\(1/9\)</span> on each pixel in the box,</p>
<div class="bigcenterimgcontainer">
<img src="img/Gimp-Blur.png" alt="" style="">
<div class="caption">
Derived from the <a href="http://docs.gimp.org/en/plug-in-convmatrix.html">Gimp documentation</a>
</div>
</div>
<div class="spaceafterimg">

</div>
<p>We can also detect edges by taking the values <span class="math">\(-1\)</span> and <span class="math">\(1\)</span> on two adjacent pixels, and zero everywhere else. That is, we subtract two adjacent pixels. When side by side pixels are similar, this is gives us approximately zero. On edges, however, adjacent pixels are very different in the direction perpendicular to the edge.</p>
<div class="bigcenterimgcontainer">
<img src="img/Gimp-Edge.png" alt="" style="">
<div class="caption">
Derived from the <a href="http://docs.gimp.org/en/plug-in-convmatrix.html">Gimp documentation</a>
</div>
</div>
<div class="spaceafterimg">

</div>
<p>The gimp documentation has <a href="http://docs.gimp.org/en/plug-in-convmatrix.html">many other examples</a>.</p>
<h1 id="convolutional-neural-networks">Convolutional Neural Networks</h1>
<p>So, how does convolution relate to convolutional neural networks?</p>
<p>Consider a 1-dimensional convolutional layer with inputs <span class="math">\(\{x_n\}\)</span> and outputs <span class="math">\(\{y_n\}\)</span>, like we discussed in the <a href="../2014-07-Conv-Nets-Modular/">previous post</a>:</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv-9-Conv2-XY.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>As we observed, we can describe the outputs in terms of the inputs:</p>
<p><span class="math">\[y_n = A(x_{n}, x_{n+1}, ...)\]</span></p>
<p>Generally, <span class="math">\(A\)</span> would be multiple neurons. But suppose it is a single neuron for a moment.</p>
<p>Recall that a typical neuron in a neural network is described by:</p>
<p><span class="math">\[\sigma(w_0x_0 + w_1x_1 + w_2x_2 ~...~ + b)\]</span></p>
<p>Where <span class="math">\(x_0\)</span>, <span class="math">\(x_1\)</span>… are the inputs. The weights, <span class="math">\(w_0\)</span>, <span class="math">\(w_1\)</span>, … describe how the neuron connects to its inputs. A negative weight means that an input inhibits the neuron from firing, while a positive weight encourages it to. The weights are the heart of the neuron, controlling its behavior.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> Saying that multiple neurons are identical is the same thing as saying that the weights are the same.</p>
<p>It’s this wiring of neurons, describing all the weights and which ones are identical, that convolution will handle for us.</p>
<p>Typically, we describe all the neurons in a layers at once, rather than individually. The trick is to have a weight matrix, <span class="math">\(W\)</span>:</p>
<p><span class="math">\[y = \sigma(Wx + b)\]</span></p>
<p>Where <span class="math">\(\sigma\)</span> denotes sigmoid or another neuron activation function.</p>
<p>For example, we get:</p>
<p><span class="math">\[y_0 = \sigma(W_{0,0}x_0 + W_{0,1}x_1 + W_{0,2}x_2 ...)\]</span></p>
<p><span class="math">\[y_1 = \sigma(W_{1,0}x_0 + W_{1,1}x_1 + W_{1,2}x_2 ...)\]</span></p>
<p>Each row of the matrix describes the weights connect a neuron to its inputs.</p>
<p>Returning to the convolutional layer, though, because there are multiple copies of the same neuron, many weights appear in multiple positions.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv-9-Conv2-XY-W.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Which corresponds to the equations:</p>
<p><span class="math">\[y_0 = \sigma(W_0x_0 + W_1x_1 -b)\]</span></p>
<p><span class="math">\[y_1 = \sigma(W_0x_1 + W_1x_2 -b)\]</span></p>
<p>So while, normally, a weight matrix connects every input to every neuron with different weights:</p>
<p><span class="math">\[W = \left[\begin{array}{ccccc} 
W_{0,0} &amp; W_{0,1} &amp; W_{0,2} &amp; W_{0,3} &amp; ...\\
W_{1,0} &amp; W_{1,1} &amp; W_{1,2} &amp; W_{1,3} &amp; ...\\
W_{2,0} &amp; W_{2,1} &amp; W_{2,2} &amp; W_{2,3} &amp; ...\\
W_{3,0} &amp; W_{3,1} &amp; W_{3,2} &amp; W_{3,3} &amp; ...\\
...     &amp;   ...   &amp;   ...   &amp;  ...    &amp; ...\\
\end{array}\right]\]</span></p>
<p>The matrix for a convolutional layer like the one above looks quite different. The same weights appear in a bunch of positions. And because neurons don’t connect to many possible inputs, there’s lots of zeros.</p>
<p><span class="math">\[W = \left[\begin{array}{ccccc} 
w_0 &amp; w_1 &amp;  0  &amp;  0  &amp; ...\\
 0  &amp; w_0 &amp; w_1 &amp;  0  &amp; ...\\
 0  &amp;  0  &amp; w_0 &amp; w_1 &amp; ...\\
 0  &amp;  0  &amp;  0  &amp; w_0 &amp; ...\\
... &amp; ... &amp; ... &amp; ... &amp; ...\\
\end{array}\right]\]</span></p>
<p>Multiplying by the above matrix is the same thing as convolving with <span class="math">\([...0, w_1, w_0, 0...]\)</span>. The function sliding to different positions corresponds to having neurons at those positions.</p>
<p>What about two-dimensional convolutional layers?</p>
<div class="centerimgcontainer">
<img src="img/Conv2-5x5-Conv2-XY.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>The wiring of a two dimensional convolutional layer corresponds to a two-dimensional convolution.</p>
<p>Consider our example of using a convolution to detect edges in an image, above, by sliding a kernel around and applying it to every patch. Just like this, a convolutional layer will apply a neuron to every patch of the image.</p>
<h1 id="conclusion">Conclusion</h1>
<p>We introduced a lot of mathematical machinery in this blog post, but it may not be obvious what we gained. Convolution is obviously a useful tool in probability theory and computer graphics, but what do we gain from phrasing convolutional neural networks in terms of convolutions?</p>
<p>The first advantage is that we have some very powerful language for describing the wiring of networks. The examples we’ve dealt with so far haven’t been complicated enough for this benefit to become clear, but convolutions will allow us to get rid of huge amounts of unpleasant book-keeping for us.</p>
<p>Secondly, convolutions come with significant implementational advantages. Many libraries provide highly efficient convolution routines. Further, while convolution naively appears to be an <span class="math">\(O(n^2)\)</span> operation, using some rather deep mathematical insights, it is possible to create a <span class="math">\(O(n\log(n))\)</span> implementation. We will discuss this in much greater detail in a future post.</p>
<p>In fact, the use of highly-efficient parallel convolution implementations on GPUs has been essential to recent progress in computer vision.</p>
<h1 id="next-posts-in-this-series">Next Posts in this Series</h1>
<p>This post is part of a series on convolutional neural networks and their generalizations. The first two posts will be review for those familiar with deep learning, while later ones should be of interest to everyone. To get updates, subscribe to my <a href="../../rss.xml">RSS feed</a>!</p>
<p>Please comment below or on the side. Pull requests can be made on <a href="https://github.com/colah/Conv-Nets-Series">github</a>.</p>
<h1 id="acknowledgments">Acknowledgments</h1>
<p>I’m extremely grateful to Eliana Lorch, for extensive discussion of convolutions and help writing this post.</p>
<p>I’m also grateful to Michael Nielsen and Dario Amodei for their comments and support.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>We want the probability of the ball rolling <span class="math">\(a\)</span> units the first time and also rolling <span class="math">\(b\)</span> units the second time. The distributions <span class="math">\(P(A) = f(a)\)</span> and <span class="math">\(P(b) = g(b)\)</span> are independent, with both distributions centered at 0. So <span class="math">\(P(a,b) = P(a) * P(b) = f(a) \cdot g(b)\)</span>.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>The non-standard definition, which I haven’t previously seen, seems to have a lot of benefits. In future posts, we will find this definition very helpful because it lends itself to generalization to new algebraic structures. But it also has the advantage that it makes a lot of algebraic properties of convolutions really obvious.</p>
<p>For example, convolution is a commutative operation. That is, <span class="math">\(f\ast g = g\ast f\)</span>. Why?</p>
<p><span class="math">\[\sum_{a+b=c} f(a) \cdot g(b) ~~=~  \sum_{b+a=c} g(b) \cdot f(a)\]</span></p>
<p>Convolution is also associative. That is, <span class="math">\((f\ast g)\ast h = f\ast (g\ast h)\)</span>. Why?</p>
<p><span class="math">\[\sum_{(a+b)+c=d} (f(a) \cdot g(b)) \cdot h(c) ~~=~ \sum_{a+(b+c)=d} f(a) \cdot (g(b) \cdot h(c))\]</span><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>There’s also the bias, which is the “threshold” for whether the neuron fires, but it’s much simpler and I don’t want to clutter this section talking about it.<a href="#fnref3">↩</a></p></li>
</ol>
</section>]]></description>
    <pubDate>Sun, 13 Jul 2014 00:00:00 UT</pubDate>
    <guid>http://colah.github.io/posts/2014-07-Understanding-Convolutions/</guid>
</item>
<item>
    <title>Conv Nets: A Modular Perspective</title>
    <link>http://colah.github.io/posts/2014-07-Conv-Nets-Modular/</link>
    <description><![CDATA[<h1 id="introduction">Introduction</h1>
<p>In the last few years, deep neural networks have lead to breakthrough results on a variety of pattern recognition problems, such as computer vision and voice recognition. One of the essential components leading to these results has been a special kind of neural network called a <em>convolutional neural network</em>.</p>
<p>At its most basic, convolutional neural networks can be thought of as a kind of neural network that uses many identical copies of the same neuron.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> This allows the network to have lots of neurons and express computationally large models while keeping the number of actual parameters – the values describing how neurons behave – that need to be learned fairly small.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv2-9x5-Conv2Conv2.png" alt="" style="">
<div class="caption">
A 2D Convolutional Neural Network
</div>
</div>
<div class="spaceafterimg">

</div>
<p>This trick of having multiple copies of the same neuron is roughly analogous to the abstraction of functions in mathematics and computer science. When programming, we write a function once and use it in many places – not writing the same code a hundred times in different places makes it faster to program, and results in fewer bugs. Similarly, a convolutional neural network can learn a neuron once and use it in many places, making it easier to learn the model and reducing error.</p>
<h1 id="structure-of-convolutional-neural-networks">Structure of Convolutional Neural Networks</h1>
<p>Suppose you want a neural network to look at audio samples and predict whether a human is speaking or not. Maybe you want to do more analysis if someone is speaking.</p>
<p>You get audio samples at different points in time. The samples are evenly spaced.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv-9-xs.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>The simplest way to try and classify them with a neural network is to just connect them all to a fully-connected layer. There are a bunch of different neurons, and every input connects to every neuron.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv-9-F.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>A more sophisticated approach notices a kind of <em>symmetry</em> in the properties it’s useful to look for in the data. We care a lot about local properties of the data: What frequency of sounds are there around a given time? Are they increasing or decreasing? And so on.</p>
<p>We care about the same properties at all points in time. It’s useful to know the frequencies at the beginning, it’s useful to know the frequencies in the middle, and it’s also useful to know the frequencies at the end. Again, note that these are local properties, in that we only need to look at a small window of the audio sample in order to determine them.</p>
<p>So, we can create a group of neurons, <span class="math">\(A\)</span>, that look at small time segments of our data.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> <span class="math">\(A\)</span> looks at all such segments, computing certain <em>features</em>. Then, the output of this <em>convolutional layer</em> is fed into a fully-connected layer, <span class="math">\(F\)</span>.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv-9-Conv2.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>In the above example, <span class="math">\(A\)</span> only looked at segments consisting of two points. This isn’t realistic. Usually, a convolution layer’s window would be much larger.</p>
<p>In the following example, <span class="math">\(A\)</span> looks at 3 points. That isn’t realistic either – sadly, it’s tricky to visualize <span class="math">\(A\)</span> connecting to lots of points.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv-9-Conv3.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>One very nice property of convolutional layers is that they’re composable. You can feed the output of one convolutional layer into another. With each layer, the network can detect higher-level, more abstract features.</p>
<p>In the following example, we have a new group of neurons, <span class="math">\(B\)</span>. <span class="math">\(B\)</span> is used to create another convolutional layer stacked on top of the previous one.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv-9-Conv2Conv2.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Convolutional layers are often interweaved with pooling layers. In particular, there is a kind of layer called a max-pooling layer that is extremely popular.</p>
<p>Often, from a high level perspective, we don’t care about the precise point in time a feature is present. If a shift in frequency occurs slightly earlier or later, does it matter?</p>
<p>A max-pooling layer takes the maximum of features over small blocks of a previous layer. The output tells us if a feature was present in a region of the previous layer, but not precisely where.</p>
<p>Max-pooling layers kind of “zoom out”. They allow later convolutional layers to work on larger sections of the data, because a small patch after the pooling layer corresponds to a much larger patch before it. They also make us invariant to some very small transformations of the data.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv-9-Conv2Max2Conv2.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<div class="floatrightimgcontainer">
<img src="img/Conv2-unit.png" alt="" style="">
</div>
<p>In our previous examples, we’ve used 1-dimensional convolutional layers. However, convolutional layers can work on higher-dimensional data as well. In fact, the most famous successes of convolutional neural networks are applying 2D convolutional neural networks to recognizing images.</p>
<p>In a 2-dimensional convolutional layer, instead of looking at segments, <span class="math">\(A\)</span> will now look at patches.</p>
<p>For each patch, <span class="math">\(A\)</span> will compute features. For example, it might learn to detect the presence of an edge. Or it might learn to detect a texture. Or perhaps a contrast between two colors.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv2-9x5-Conv2.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>In the previous example, we fed the output of our convolutional layer into a fully-connected layer. But we can also compose two convolutional layers, as we did in the one dimensional case.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv2-9x5-Conv2Conv2.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>We can also do max pooling in two dimensions. Here, we take the maximum of features over a small patch.</p>
<p>What this really boils down to is that, when considering an entire image, we don’t care about the exact position of an edge, down to a pixel. It’s enough to know where it is to within a few pixels.</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv2-9x5-Conv2Max2Conv2.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Three-dimensional convolutional networks are also sometimes used, for data like videos or volumetric data (eg. 3D medical scans). However, they are not very widely used, and much harder to visualize.</p>
<p>Now, we previously said that <span class="math">\(A\)</span> was a group of neurons. We should be a bit more precise about this: what is <span class="math">\(A\)</span> exactly?</p>
<p>In traditional convolutional layers, <span class="math">\(A\)</span> is a bunch of neurons in parallel, that all get the same inputs and compute different features.</p>
<p>For example, in a 2-dimensional convolutional layer, one neuron might detect horizontal edges, another might detect vertical edges, and another might detect green-red color contrasts.</p>
<div class="centerimgcontainer">
<img src="img/Conv-A.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>That said, in the recent paper ‘Network in Network’ (<a href="http://arxiv.org/abs/1312.4400">Lin <em>et al.</em> (2013)</a>), a new “Mlpconv” layer is proposed. In this model, <span class="math">\(A\)</span> would have multiple layers of neurons, with the final layer outputting higher level features for the region. In the paper, the model achieves some very impressive results, setting new state of the art on a number of benchmark datasets.</p>
<div class="centerimgcontainer">
<img src="img/Conv-A-NIN.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>That said, for the purposes of this post, we will focus on standard convolutional layers. There’s already enough for us to consider there!</p>
<h1 id="results-of-convolutional-neural-networks">Results of Convolutional Neural Networks</h1>
<p>Earlier, we alluded to recent breakthroughs in computer vision using convolutional neural networks. Before we go on, I’d like to briefly discuss some of these results as motivation.</p>
<p>In 2012, Alex Krizhevsky, Ilya Sutskever, and Geoff Hinton blew existing image classification results out of the water (<a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizehvsky <em>et al.</em> (2012)</a>).</p>
<p>Their progress was the result of combining together a bunch of different pieces. They used GPUs to train a very large, deep, neural network. They used a new kind of neuron (ReLUs) and a new technique to reduce a problem called ‘overfitting’ (DropOut). They used a very large dataset with lots of image categories (<a href="http://www.image-net.org/">ImageNet</a>). And, of course, it was a convolutional neural network.</p>
<p>Their architecture, illustrated below, was very deep. It has 5 convolutional layers,<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> with pooling interspersed, and three fully-connected layers. The early layers are split over the two GPUs.</p>
<div class="bigcenterimgcontainer">
<img src="img/KSH-arch.png" alt="" style="">
<div class="caption">
From <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizehvsky <em>et al.</em> (2012)</a>
</div>
</div>
<div class="spaceafterimg">

</div>
<p>They trained their network to classify images into a thousand different categories.</p>
<p>Randomly guessing, one would guess the correct answer 0.1% of the time. Krizhevsky, <em>et al.</em>’s model is able to give the right answer 63% of the time. Further, one of the top 5 answers it gives is right 85% of the time!</p>
<div class="bigcenterimgcontainer">
<img src="img/KSH-results.png" alt="" style="">
<div class="caption">
Top: 4 correctly classified examples. Bottom: 4 incorrectly classified examples. Each example has an image, followed by its label, followed by the top 5 guesses with probabilities. From <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizehvsky <em>et al.</em> (2012)</a>.
</div>
</div>
<div class="spaceafterimg">

</div>
<p>Even some of its errors seem pretty reasonable to me!</p>
<p>We can also examine what the first layer of the network learns to do.</p>
<p>Recall that the convolutional layers were split between the two GPUs. Information doesn’t go back and forth each layer, so the split sides are disconnected in a real way. It turns out that, every time the model is run, the two sides specialize.</p>
<div class="bigcenterimgcontainer">
<img src="img/KSH-filters.png" alt="" style="">
<div class="caption">
Filters learned by the first convolutional layer. The top half corresponds to the layer on one GPU, the bottom on the other. From <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizehvsky <em>et al.</em> (2012)</a>
</div>
</div>
<div class="spaceafterimg">

</div>
<p>Neurons in one side focus on black and white, learning to detect edges of different orientations and sizes. Neurons on the other side specialize on color and texture, detecting color contrasts and patterns.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> Remember that the neurons are <em>randomly</em> initialized. No human went and set them to be edge detectors, or to split in this way. It arose simply from training the network to classify images.</p>
<p>These remarkable results (and other exciting results around that time) were only the beginning. They were quickly followed by a lot of other work testing modified approaches and gradually improving the results, or applying them to other areas. And, in addition to the neural networks community, many in the computer vision community have adopted deep convolutional neural networks.</p>
<p>Convolutional neural networks are an essential tool in computer vision and modern pattern recognition.</p>
<!---
<div class="centerimgcontainer">
<img src="img/KSH-similar.png" alt="" style="">
<div class="caption">From [Krizehvsky *et al.* (2012)]</div>
</div>
<div class="spaceafterimg"></div>
--->


<h1 id="formalizing-convolutional-neural-networks">Formalizing Convolutional Neural Networks</h1>
<p>Consider a 1-dimensional convolutional layer with inputs <span class="math">\(\{x_n\}\)</span> and outputs <span class="math">\(\{y_n\}\)</span>:</p>
<div class="bigcenterimgcontainer">
<img src="img/Conv-9-Conv2-XY.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>It’s relatively easy to describe the outputs in terms of the inputs:</p>
<p><span class="math">\[y_n = A(x_{n}, x_{n+1}, ...)\]</span></p>
<p>For example, in the above:</p>
<p><span class="math">\[y_0 = A(x_0, x_1)\]</span> <span class="math">\[y_1 = A(x_1, x_2)\]</span></p>
<p>Similarly, if we consider a 2-dimensional convolutional layer, with inputs <span class="math">\(\{x_{n,m}\}\)</span> and outputs <span class="math">\(\{y_{n,m}\}\)</span>:</p>
<div class="centerimgcontainer">
<img src="img/Conv2-5x5-Conv2-XY.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>We can, again, write down the outputs in terms of the inputs:</p>
<p><span class="math">\[y_{n,m} = A\left(\begin{array}{ccc} x_{n,~m}, &amp; x_{n+1,~m},&amp; ...,~\\ x_{n,~m+1}, &amp; x_{n+1,~m+1}, &amp; ..., ~\\ &amp;...\\\end{array}\right)\]</span></p>
<p>For example:</p>
<p><span class="math">\[y_{0,0} = A\left(\begin{array}{cc} x_{0,~0}, &amp; x_{1,~0},~\\ x_{0,~1}, &amp; x_{1,~1}~\\\end{array}\right)\]</span> <span class="math">\[y_{1,0} = A\left(\begin{array}{cc} x_{1,~0}, &amp; x_{2,~0},~\\ x_{1,~1}, &amp; x_{2,~1}~\\\end{array}\right)\]</span></p>
<p>If one combines this with the equation for <span class="math">\(A(x)\)</span>,</p>
<p><span class="math">\[A(x) = \sigma(Wx + b)\]</span></p>
<p>one has everything they need to implement a convolutional neural network, at least in theory.</p>
<p>In practice, this is often not best way to think about convolutional neural networks. There is an alternative formulation, in terms of a mathematical operation called <em>convolution</em>, that is often more helpful.</p>
<p>The convolution operation is a powerful tool. In mathematics, it comes up in diverse contexts, ranging from the study of partial differential equations to probability theory. In part because of its role in PDEs, convolution is very important in the physical sciences. It also has an important role in many applied areas, like computer graphics and signal processing.</p>
<p>For us, convolution will provide a number of benefits. Firstly, it will allow us to create much more efficient implementations of convolutional layers than the naive perspective might suggest. Secondly, it will remove a lot of messiness from our formulation, handling all the bookkeeping presently showing up in the indexing of <span class="math">\(x\)</span>s – the present formulation may not seem messy yet, but that’s only because we haven’t got into the tricky cases yet. Finally, convolution will give us a significantly different perspective for reasoning about convolutional layers.</p>
<blockquote>
<p>I admire the elegance of your method of computation; it must be nice to ride through these fields upon the horse of true mathematics while the like of us have to make our way laboriously on foot.  — Albert Einstein</p>
</blockquote>
<h1 id="next-posts-in-this-series">Next Posts in this Series</h1>
<p><a href="../2014-07-Understanding-Convolutions/"><strong>Read the next post!</strong></a></p>
<p>This post is part of a series on convolutional neural networks and their generalizations. The first two posts will be review for those familiar with deep learning, while later ones should be of interest to everyone. To get updates, subscribe to my <a href="../../rss.xml">RSS feed</a>!</p>
<p>Please comment below or on the side. Pull requests can be made on <a href="https://github.com/colah/Conv-Nets-Series">github</a>.</p>
<h1 id="acknowledgments">Acknowledgments</h1>
<p>I’m grateful to Eliana Lorch, Aaron Courville, and Sebastian Zany for their comments and support.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>It should be noted that not all neural networks that use multiple copies of the same neuron are convolutional neural networks. Convolutional neural networks are just one type of neural network that uses the more general trick, <em>weight-tying</em>. Other kinds of neural network that do this are recurrent neural networks and recursive neural networks.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Groups of neurons, like <span class="math">\(A\)</span>, that appear in multiple places are sometimes called <em>modules</em>, and networks that use them are sometimes called <em>modular neural networks</em>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>They also test using 7 in the paper.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>This seems to have interesting analogies to rods and cones in the retina.<a href="#fnref4">↩</a></p></li>
</ol>
</section>]]></description>
    <pubDate>Tue, 08 Jul 2014 00:00:00 UT</pubDate>
    <guid>http://colah.github.io/posts/2014-07-Conv-Nets-Modular/</guid>
</item>
<item>
    <title>Deep Learning, NLP, and Representations</title>
    <link>http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/</link>
    <description><![CDATA[<h1 id="introduction">Introduction</h1>
<p>In the last few years, deep neural networks have dominated pattern recognition. They blew the previous state of the art out of the water for many computer vision tasks. Voice recognition is also moving that way.</p>
<p>But despite the results, we have to wonder… why do they work so well?</p>
<p>This post reviews some extremely remarkable results in applying deep neural networks to natural language processing (NLP). In doing so, I hope to make accessible one promising answer as to why deep neural networks work. I think it’s a very elegant perspective.</p>
<h1 id="one-hidden-layer-neural-networks">One Hidden Layer Neural Networks</h1>
<p>A neural network with a hidden layer has universality: given enough hidden units, it can approximate any function. This is a frequently quoted – and even more frequently, misunderstood and applied – theorem.</p>
<p>It’s true, essentially, because the hidden layer can be used as a lookup table.</p>
<p>For simplicity, let’s consider a perceptron network. A <a href="http://en.wikipedia.org/wiki/Perceptron">perceptron</a> is a very simple neuron that fires if it exceeds a certain threshold and doesn’t fire if it doesn’t reach that threshold. A perceptron network gets binary (0 and 1) inputs and gives binary outputs.</p>
<p>Note that there are only a finite number of possible inputs. For each possible input, we can construct a neuron in the hidden layer that fires for that input,<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> and only on that specific input. Then we can use the connections between that neuron and the output neurons to control the output in that specific case. <a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<div class="centerimgcontainer">
<img src="img/flowchart-PerceptronLookup.png" alt="" style="">
</div>
<p>And so, it’s true that one hidden layer neural networks are universal. But there isn’t anything particularly impressive or exciting about that. Saying that your model can do the same thing as a lookup table isn’t a very strong argument for it. It just means it isn’t <em>impossible</em> for your model to do the task.</p>
<p>Universality means that a network can fit to any training data you give it. It doesn’t mean that it will interpolate to new data points in a reasonable way.</p>
<p>No, universality isn’t an explanation for why neural networks work so well. The real reason seems to be something much more subtle… And, to understand it, we’ll first need to understand some concrete results.</p>
<h1 id="word-embeddings">Word Embeddings</h1>
<p>I’d like to start by tracing a particularly interesting strand of deep learning research: word embeddings. In my personal opinion, word embeddings are one of the most exciting area of research in deep learning at the moment, although they were originally introduced by Bengio, <em>et al.</em> more than a decade ago.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> Beyond that, I think they are one of the best places to gain intuition about why deep learning is so effective.</p>
<p>A word embedding <span class="math">\(W: \mathrm{words} \to \mathbb{R}^n\)</span> is a paramaterized function mapping words in some language to high-dimensional vectors (perhaps 200 to 500 dimensions). For example, we might find:</p>
<p><span class="math">\[W(``\text{cat}\!&quot;) = (0.2,~ \text{-}0.4,~ 0.7,~ ...)\]</span></p>
<p><span class="math">\[W(``\text{mat}\!&quot;) = (0.0,~ 0.6,~ \text{-}0.1,~ ...)\]</span></p>
<p>(Typically, the function is a lookup table, parameterized by a matrix, <span class="math">\(\theta\)</span>, with a row for each word: <span class="math">\(W_\theta(w_n) = \theta_n\)</span>.)</p>
<p><span class="math">\(W\)</span> is initialized to have random vectors for each word. It learns to have meaningful vectors in order to perform some task.</p>
<p>For example, one task we might train a network for is predicting whether a 5-gram (sequence of five words) is ‘valid.’ We can easily get lots of 5-grams from Wikipedia (eg. “cat sat on the mat”) and then ‘break’ half of them by switching a word with a random word (eg. “cat sat <strong>song</strong> the mat”), since that will almost certainly make our 5-gram nonsensical.</p>
<div class="floatrightimgcontainer">
<img src="img/Bottou-WordSetup.png" alt="" style="">
<div class="caption">
Modular Network to determine if a 5-gram is ‘valid’ (From <a href="http://arxiv.org/pdf/1102.1808v3.pdf">Bottou (2011)</a>)
</div>
</div>
<div class="spaceafterimg">

</div>
<p>The model we train will run each word in the 5-gram through <span class="math">\(W\)</span> to get a vector representing it and feed those into another ‘module’ called <span class="math">\(R\)</span> which tries to predict if the 5-gram is ‘valid’ or ‘broken.’ Then, we’d like:</p>
<p><span class="math">\[R(W(``\text{cat}\!&quot;),~ W(``\text{sat}\!&quot;),~ W(``\text{on}\!&quot;),~ W(``\text{the}\!&quot;),~ W(``\text{mat}\!&quot;)) = 1\]</span></p>
<p><span class="math">\[R(W(``\text{cat}\!&quot;),~ W(``\text{sat}\!&quot;),~ W(``\text{song}\!&quot;),~ W(``\text{the}\!&quot;),~ W(``\text{mat}\!&quot;)) = 0\]</span></p>
<p>In order to predict these values accurately, the network needs to learn good parameters for both <span class="math">\(W\)</span> and <span class="math">\(R\)</span>.</p>
<p>Now, this task isn’t terribly interesting. Maybe it could be helpful in detecting grammatical errors in text or something. But what is extremely interesting is <span class="math">\(W\)</span>.</p>
<p>(In fact, to us, the entire point of the task is to learn <span class="math">\(W\)</span>. We could have done several other tasks – another common one is predicting the next word in the sentence. But we don’t really care. In the remainder of this section we will talk about many word embedding results and won’t distinguish between different approaches.)</p>
<p>One thing we can do to get a feel for the word embedding space is to visualize them with <a href="http://homepage.tudelft.nl/19j49/t-SNE.html">t-SNE</a>, a sophisticated technique for visualizing high-dimensional data.</p>
<div class="bigcenterimgcontainer">
<img src="img/Turian-WordTSNE.png" alt="" style="">
<div class="caption">
t-SNE visualizations of word embeddings. Left: Number Region; Right: Jobs Region. From <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/turian-wordrepresentations-acl10.pdf">Turian <em>et al.</em> (2010)</a>, see <a href="http://metaoptimize.s3.amazonaws.com/cw-embeddings-ACL2010/embeddings-mostcommon.EMBEDDING_SIZE=50.png">complete image</a>.
</div>
</div>
<div class="spaceafterimg">

</div>
<p>This kind of ‘map’ of words makes a lot of intuitive sense to us. Similar words are close together. Another way to get at this is to look at which words are closest in the embedding to a given word. Again, the words tend to be quite similar.</p>
<div class="bigcenterimgcontainer">
<img src="img/Colbert-WordTable2.png" alt="" style="">
<div class="caption">
What words have embeddings closest to a given word? From <a href="http://arxiv.org/pdf/1103.0398v1.pdf">Collobert <em>et al.</em> (2011)</a>
</div>
</div>
<div class="spaceafterimg">

</div>
<p>It seems natural for a network to make words with similar meanings have similar vectors. If you switch a word for a synonym (eg. “a few people sing well” <span class="math">\(\to\)</span> “a <em>couple</em> people sing well”), the validity of the sentence doesn’t change. While, from a naive perspective, the input sentence has changed a lot, if <span class="math">\(W\)</span> maps synonyms (like “few” and “couple”) close together, from <span class="math">\(R\)</span>’s perspective little changes.</p>
<p>This is very powerful. The number of possible 5-grams is massive and we have a comparatively small number of data points to try to learn from. Similar words being close together allows us to generalize from one sentence to a class of similar sentences. This doesn’t just mean switching a word for a synonym, but also switching a word for a word in a similar class (eg. “the wall is blue” <span class="math">\(\to\)</span> “the wall is <em>red</em>”). Further, we can change multiple words (eg. “the wall is blue” <span class="math">\(\to\)</span> “the <em>ceiling</em> is <em>red</em>”). The impact of this is exponential with respect to the number of words.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<p>So, clearly this is a very useful thing for <span class="math">\(W\)</span> to do. But how does it learn to do this? It seems quite likely that there are lots of situations where it has seen a sentence like “the wall is blue” and know that it is valid before it sees a sentence like “the wall is red”. As such, shifting “red” a bit closer to “blue” makes the network perform better.</p>
<p>We still need to see examples of every word being used, but the analogies allow us to generalize to new combinations of words. You’ve seen all the words that you understand before, but you haven’t seen all the sentences that you understand before. So too with neural networks.</p>
<div class="floatrightimgcontainer">
<img src="img/Mikolov-GenderVecs.png" alt="" style="">
<div class="caption">
From <a href="https://www.aclweb.org/anthology/N/N13/N13-1090.pdf">Mikolov <em>et al.</em> (2013a)</a>
</div>
</div>
<p>Word embeddings exhibit an even more remarkable property: analogies between words seem to be encoded in the difference vectors between words. For example, there seems to be a constant male-female difference vector:</p>
<p><span class="math">\[W(``\text{woman}\!&quot;) - W(``\text{man}\!&quot;) ~\simeq~ W(``\text{aunt}\!&quot;) - W(``\text{uncle}\!&quot;)\]</span> <span class="math">\[W(``\text{woman}\!&quot;) - W(``\text{man}\!&quot;) ~\simeq~ W(``\text{queen}\!&quot;) - W(``\text{king}\!&quot;)\]</span></p>
<p>This may not seem too surprising. After all, gender pronouns mean that switching a word can make a sentence grammatically incorrect. You write, “<em>she</em> is the aunt” but “<em>he</em> is the uncle.” Similarly, “<em>he</em> is the King” but “<em>she</em> is the Queen.” If one sees “<em>she</em> is the <em>uncle</em>,” the most likely explanation is a grammatical error. If words are being randomly switched half the time, it seems pretty likely that happened here.</p>
<p>“Of course!” We say with hindsight, “the word embedding will learn to encode gender in a consistent way. In fact, there’s probably a gender dimension. Same thing for singular vs plural. It’s easy to find these trivial relationships!”</p>
<p>It turns out, though, that much more sophisticated relationships are also encoded in this way. It seems almost miraculous!</p>
<div class="bigcenterimgcontainer">
<img src="img/Mikolov-AnalogyTable.png" alt="" style="">
<div class="caption">
Relationship pairs in a word embedding. From <a href="http://arxiv.org/pdf/1301.3781.pdf">Mikolov <em>et al.</em> (2013b)</a>.
</div>
</div>
<div class="spaceafterimg">

</div>
<p>It’s important to appreciate that all of these properties of <span class="math">\(W\)</span> are <em>side effects</em>. We didn’t try to have similar words be close together. We didn’t try to have analogies encoded with difference vectors. All we tried to do was perform a simple task, like predicting whether a sentence was valid. These properties more or less popped out of the optimization process.</p>
<p>This seems to be a great strength of neural networks: they learn better ways to represent data, automatically. Representing data well, in turn, seems to be essential to success at many machine learning problems. Word embeddings are just a particularly striking example of learning a representation.</p>
<h1 id="shared-representations">Shared Representations</h1>
<p>The properties of word embeddings are certainly interesting, but can we do anything useful with them? Besides predicting silly things, like whether a 5-gram is ‘valid’?</p>
<div class="floatrightimgcontainer">
<img src="img/flowchart-TranfserLearning2.png" alt="" style="">
<div class="caption">
<span class="math">\(W\)</span> and <span class="math">\(F\)</span> learn to perform task A. Later, <span class="math">\(G\)</span> can learn to perform B based on <span class="math">\(W\)</span>.
</div>
</div>
<p>We learned the word embedding in order to do well on a simple task, but based on the nice properties we’ve observed in word embeddings, you may suspect that they could be generally useful in NLP tasks. In fact, word representations like these are extremely important:</p>
<blockquote>
<p>The use of word representations… has become a key “secret sauce” for the success of many NLP systems in recent years, across tasks including named entity recognition, part-of-speech tagging, parsing, and semantic role labeling. (<a href="http://nlp.stanford.edu/~lmthang/data/papers/conll13_morpho.pdf">Luong <em>et al.</em> (2013)</a>)</p>
</blockquote>
<p>This general tactic – learning a good representation on a task A and then using it on a task B – is one of the major tricks in the Deep Learning toolbox. It goes by different names depending on the details: pretraining, transfer learning, and multi-task learning. One of the great strengths of this approach is that it allows the representation to learn from more than one kind of data.</p>
<p>There’s a counterpart to this trick. Instead of learning a way to represent one kind of data and using it to perform multiple kinds of tasks, we can learn a way to map multiple kinds of data into a single representation!</p>
<p>One nice example of this is a bilingual word-embedding, produced in <a href="http://ai.stanford.edu/~wzou/emnlp2013_ZouSocherCerManning.pdf">Socher <em>et al.</em> (2013a)</a>. We can learn to embed words from two different languages in a single, shared space. In this case, we learn to embed English and Mandarin Chinese words in the same space.</p>
<div class="floatrightimgcontainer">
<img src="img/flowchart-bilingual.png" alt="" style="">
</div>
<p>We train two word embeddings, <span class="math">\(W_{en}\)</span> and <span class="math">\(W_{zh}\)</span> in a manner similar to how we did above. However, we know that certain English words and Chinese words have similar meanings. So, we optimize for an additional property: words that we know are close translations should be close together.</p>
<p>Of course, we observe that the words we knew had similar meanings end up close together. Since we optimized for that, it’s not surprising. More interesting is that words we <em>didn’t know</em> were translations end up close together.</p>
<p>In light of our previous experiences with word embeddings, this may not seem too surprising. Word embeddings pull similar words together, so if an English and Chinese word we know to mean similar things are near each other, their synonyms will also end up near each other. We also know that things like gender differences tend to end up being represented with a constant difference vector. It seems like forcing enough points to line up should force these difference vectors to be the same in both the English and Chinese embeddings. A result of this would be that if we know that two male versions of words translate to each other, we should also get the female words to translate to each other.</p>
<p>Intuitively, it feels a bit like the two languages have a similar ‘shape’ and that by forcing them to line up at different points, they overlap and other points get pulled into the right positions.</p>
<div class="centerimgcontainer">
<img src="img/Socher-BillingualTSNE.png" alt="" style="">
<div class="caption">
t-SNE visualization of the bilingual word embedding. Green is Chinese, Yellow is English. (<a href="http://ai.stanford.edu/~wzou/emnlp2013_ZouSocherCerManning.pdf">Socher <em>et al.</em> (2013a)</a>)
</div>
</div>
<p>In bilingual word embeddings, we learn a shared representation for two very similar kinds of data. But we can also learn to embed very different kinds of data in the same space.</p>
<div class="floatrightimgcontainer">
<img src="img/flowchart-DeViSE.png" alt="" style="">
</div>
<p>Recently, deep learning has begun exploring models that embed images and words in a single representation.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
<p>The basic idea is that one classifies images by outputting a vector in a word embedding. Images of dogs are mapped near the “dog” word vector. Images of horses are mapped near the “horse” vector. Images of automobiles near the “automobile” vector. And so on.</p>
<p>The interesting part is what happens when you test the model on new classes of images. For example, if the model wasn’t trained to classify cats – that is, to map them near the “cat” vector – what happens when we try to classify images of cats?</p>
<div class="centerimgcontainer">
<img src="img/Socher-ImageClassManifold.png" alt="" style="">
<div class="caption">
(<a href="http://nlp.stanford.edu/~socherr/SocherGanjooManningNg_NIPS2013.pdf">Socher <em>et al.</em> (2013b)</a>)
</div>
</div>
<p>It turns out that the network is able to handle these new classes of images quite reasonably. Images of cats aren’t mapped to random points in the word embedding space. Instead, they tend to be mapped to the general vicinity of the “dog” vector, and, in fact, close to the “cat” vector. Similarly, the truck images end up relatively close to the “truck” vector, which is near the related “automobile” vector.</p>
<div class="bigcenterimgcontainer">
<img src="img/Socher-ImageClass-tSNE.png" alt="" style="">
<div class="caption">
(<a href="http://nlp.stanford.edu/~socherr/SocherGanjooManningNg_NIPS2013.pdf">Socher <em>et al.</em> (2013b)</a>)
</div>
</div>
<p>This was done by members of the Stanford group with only 8 known classes (and 2 unknown classes). The results are already quite impressive. But with so few known classes, there are very few points to interpolate the relationship between images and semantic space off of.</p>
<!-- (from KSH)?? -->

<p>The Google group did a much larger version – instead of 8 categories, they used 1,000 – around the same time (<a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41473.pdf">Frome <em>et al.</em> (2013)</a>) and has followed up with a new variation (<a href="http://arxiv.org/pdf/1312.5650.pdf">Norouzi <em>et al.</em> (2014)</a>). Both are based on a very powerful image classification model (from <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizehvsky <em>et al.</em> (2012)</a>), but embed images into the word embedding space in different ways.</p>
<p>The results are impressive. While they may not get images of unknown classes to the precise vector representing that class, they are able to get to the right neighborhood. So, if you ask it to classify images of unknown classes and the classes are fairly different, it can distinguish between the different classes.</p>
<p>Even though I’ve never seen a Aesculapian snake or an Armadillo before, if you show me a picture of one and a picture of the other, I can tell you which is which because I have a general idea of what sort of animal is associated with each word. These networks can accomplish the same thing.</p>
<p><em>(These results all exploit a sort of “these words are similar” reasoning. But it seems like much stronger results should be possible based on relationships between words. In our word embedding space, there is a consistent difference vector between male and female version of words. Similarly, in image space, there are consistent features distinguishing between male and female. Beards, mustaches, and baldness are all strong, highly visible indicators of being male. Breasts and, less reliably, long hair, makeup and jewelery, are obvious indicators of being female.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> Even if you’ve never seen a king before, if the queen, determined to be such by the presence of a crown, suddenly has a beard, it’s pretty reasonable to give the male version.)</em></p>
<p>Shared embeddings are an extremely exciting area of research and drive at why the representation focused perspective of deep learning is so compelling.</p>
<h1 id="recursive-neural-networks">Recursive Neural Networks</h1>
<p>We began our discussion of word embeddings with the following network:</p>
<div class="centerimgcontainer">
<img src="img/Bottou-WordSetup.png" alt="" style="">
<div class="caption">
Modular Network that learns word embeddings (From <a href="http://arxiv.org/pdf/1102.1808v3.pdf">Bottou (2011)</a>)
</div>
</div>
<div class="spaceafterimg">

</div>
<p>The above diagram represents a <em>modular</em> network, <span class="math">\(R(W(w_1),~ W(w_2),~ W(w_3),~ W(w_4),~ W(w_5))\)</span>. It is built from two modules, <span class="math">\(W\)</span> and <span class="math">\(R\)</span>. This approach, of building neural networks from smaller neural network “modules” that can be composed together, is not very wide spread. It has, however, been very successful in NLP.</p>
<p>Models like the above are powerful, but they have an unfortunate limitation: they can only have a fixed number of inputs.</p>
<p>We can overcome this by adding an association module, <span class="math">\(A\)</span>, which will take two word or phrase representations and merge them.</p>
<div class="centerimgcontainer">
<img src="img/Bottou-Afold.png" alt="" style="">
<div class="caption">
(From <a href="http://arxiv.org/pdf/1102.1808v3.pdf">Bottou (2011)</a>)
</div>
</div>
<div class="spaceafterimg">

</div>
<p>By merging sequences of words, <span class="math">\(A\)</span> takes us from representing words to representing phrases or even representing whole <em>sentences</em>! And because we can merge together different numbers of words, we don’t have to have a fixed number of inputs.</p>
<p>It doesn’t necessarily make sense to merge together words in a sentence linearly. If one considers the phrase “the cat sat on the mat”, it can naturally be bracketed into segments: “((the cat) (sat (on (the mat))”. We can apply <span class="math">\(A\)</span> based on this bracketing:</p>
<div class="bigcenterimgcontainer">
<img src="img/Bottou-Atree.png" alt="" style="">
<div class="caption">
(From <a href="http://arxiv.org/pdf/1102.1808v3.pdf">Bottou (2011)</a>)
</div>
</div>
<div class="spaceafterimg">

</div>
<p>These models are often called “recursive neural networks” because one often has the output of a module go into a module of the same type. They are also sometimes called “tree-structured neural networks.”</p>
<p>Recursive neural networks have had significant successes in a number of NLP tasks. For example, <a href="http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf">Socher <em>et al.</em> (2013c)</a> uses a recursive neural network to predict sentence sentiment:</p>
<div class="bigcenterimgcontainer">
<img src="img/Socher-SentimentTree.png" alt="" style="">
<div class="caption">
(From <a href="http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf">Socher <em>et al.</em> (2013c)</a>)
</div>
</div>
<div class="spaceafterimg">

</div>
<p>One major goal has been to create a <em>reversible</em> sentence representation, a representation that one can reconstruct an actual sentence from, with roughly the same meaning. For example, we can try to introduce a disassociation module, <span class="math">\(D\)</span>, that tries to undo <span class="math">\(A\)</span>:</p>
<div class="bigcenterimgcontainer">
<img src="img/Bottou-unfold.png" alt="" style="">
<div class="caption">
(From <a href="http://arxiv.org/pdf/1102.1808v3.pdf">Bottou (2011)</a>)
</div>
</div>
<div class="spaceafterimg">

</div>
<p>If we could accomplish such a thing, it would be an extremely powerful tool. For example, we could try to make a bilingual sentence representation and use it for translation.</p>
<p>Unfortunately, this turns out to be very difficult. Very very difficult. And given the tremendous promise, there are lots of people working on it.</p>
<p>Recently, <a href="http://arxiv.org/pdf/1406.1078v1.pdf">Cho <em>et al.</em> (2014)</a> have made some progress on representing phrases, with a model that can encode English phrases and decode them in French. Look at the phrase representations it learns!</p>
<div class="bigcenterimgcontainer">
<img src="img/Cho-TimePhrase-TSNE.png" alt="" style="">
<div class="caption">
Small section of the t-SNE of the phrase representation <br /> (From <a href="http://arxiv.org/pdf/1406.1078v1.pdf">Cho <em>et al.</em> (2014)</a>)
</div>
</div>
<div class="spaceafterimg">

</div>
<h1 id="criticisms">Criticisms</h1>
<p>I’ve heard some of the results reviewed above criticized by researchers in other fields, in particular, in NLP and linguistics. The concerns are not with the results themselves, but the conclusions drawn from them, and how they compare to other techniques.</p>
<p>I don’t feel qualified to articulate these concerns. I’d encourage someone who feels this way to describe the concerns in the comments.</p>
<h1 id="conclusion">Conclusion</h1>
<p>The representation perspective of deep learning is a powerful view that seems to answer why deep neural networks are so effective. Beyond that, I think there’s something extremely beautiful about it: why are neural networks effective? Because better ways of representing data can pop out of optimizing layered models.</p>
<p>Deep learning is a very young field, where theories aren’t strongly established and views quickly change. That said, it is my impression that the representation-focused perspective of neural networks is presently very popular.</p>
<p>This post reviews a lot of research results I find very exciting, but my main motivation is to set the stage for a future post exploring connections between deep learning, type theory and functional programming. If you’re interested, you can subscribe to my <a href="../../rss.xml">rss feed</a> so that you’ll see it when it is published.</p>
<p><em>(I would be delighted to hear your comments and thoughts: you can comment inline or at the end. For typos, technical errors, or clarifications you would like to see added, you are encouraged to make a pull request on <a href="https://github.com/colah/NLP-RNNs-Representations-Post">github</a>)</em></p>
<h1 id="acknowledgments">Acknowledgments</h1>
<p>I’m grateful to Eliana Lorch, Yoshua Bengio, Michael Nielsen, Laura Ball, Rob Gilson, and Jacob Steinhardt for their comments and support.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Constructing a case for every possible input requires <span class="math">\(2^n\)</span> hidden neurons, when you have <span class="math">\(n\)</span> input neurons. In reality, the situation isn’t usually that bad. You can have cases that encompass multiple inputs. And you can have overlapping cases that add together to achieve the right input on their intersection.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>(It isn’t only perceptron networks that have universality. Networks of sigmoid neurons (and other activation functions) are also universal: give enough hidden neurons, they can approximate any continuous function arbitrarily well. Seeing this is significantly trickier because you can’t just isolate inputs.)<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Word embeddings were originally developed in (<a href="http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/64">Bengio et al, 2001</a>; <a href="http://machinelearning.wustl.edu/mlpapers/paper_files/BengioDVJ03.pdf">Bengio et al, 2003</a>), a few years before the 2006 deep learning renewal, at a time when neural networks were out of fashion. The idea of distributed representations for symbols is even older, e.g. (<a href="http://www.cogsci.ucsd.edu/~ajyu/Teaching/Cogs202_sp13/Readings/hinton86.pdf">Hinton 1986</a>).&quot;<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>The seminal paper, <a href="http://machinelearning.wustl.edu/mlpapers/paper_files/BengioDVJ03.pdf"><em>A Neural Probabilistic Language Model</em> (Bengio, <em>et al.</em> 2003)</a> has a great deal of insight about why word embeddings are powerful.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Previous work has been done modeling the joint distributions of tags and images, but it took a very different perspective.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>I’m very conscious that physical indicators of gender can be misleading. I don’t mean to imply, for example, that everyone who is bald is male or everyone who has breasts is female. Just that these often indicate such, and greatly adjust our prior.<a href="#fnref6">↩</a></p></li>
</ol>
</section>]]></description>
    <pubDate>Mon, 07 Jul 2014 00:00:00 UT</pubDate>
    <guid>http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/</guid>
</item>
<item>
    <title>Fanfiction, Graphs, and PageRank</title>
    <link>http://colah.github.io/posts/2014-07-FFN-Graphs-Vis/</link>
    <description><![CDATA[<p>On a website called fanfiction.net, users write millions of stories about their favorite stories. They have diverse opinions about them. They love some stories, and hate others. The opinions are noisy, and it’s hard to see the big picture.</p>
<p>With tools from mathematics and some helpful software, however, we can visualize the underlying structure.</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-HP-ships-labeled.png" alt="" style="">
<div class="caption">
Graph of Harry Potter Fanfiction, colored by ship
</div>
</div>
<div class="spaceafterimg">

</div>
<p>In the following post, we will visualize the Harry Potter, Naruto and Twilight fandoms on fanfiction.net. We will also use Google’s PageRank algorithm to rank stories, and perform collaborative filtering to make story recommendations to top fanfiction.net users.</p>
<p>If you’re not interested in the details, you can skip to the following:</p>
<p><strong>Interactive Graphs</strong>: <a href="graphs/HP-ship/">Harry Potter</a>, <a href="graphs/NAR-ship/">Naruto</a>, <a href="graphs/TWI-ship/">Twilight</a></p>
<p><strong>Story Rankings</strong>: <a href="pagerank/hp.html">Harry Potter</a>, <a href="pagerank/naruto.html">Naruto</a>, <a href="pagerank/twi.html">Twilight</a></p>
<p><strong>Story Recommendations</strong>: <a href="recs/hp.html">Harry Potter</a>, <a href="recs/nar.html">Naruto</a>, <a href="recs/twi.html">Twilight</a></p>
<p>And of course, you might skim below to see the pretty pictures!</p>
<h2 id="introduction">Introduction</h2>
<p>Fanfiction is a wide-spread phenomenon where fans of different works write derivative stories. This ranges from young children writing their first stories about their favorite fictional characters, to professional-quality stories written by aspiring novelists. Many such stories are posted to websites where they are read by a large audience and commented on. The largest such website is <a href="https://www.fanfiction.net/">fanficiton.net</a>.</p>
<p>The sheer amount of fanfiction out there is rather staggering. The total number of stories on fanfiction.net exceeds six million. Harry Potter stories account for around 14% of these, followed by Naruto (around 7%) and Twilight (around 4%) (<a href="http://ffnresearch.blogspot.com/2010/07/fanfictionnet-story-totals.html">FFN Research</a>). The majority of these stories have very little in the way of readership, but popular stories can have a large number of readers.</p>
<p>Some research was done into the demographics of fanfiction.net users and other topics by <a href="http://ffnresearch.blogspot.com/">FFN Research</a>. They found that 78% of fanfiction.net authors who joined in 2010 identified as female. Further, around 80% of users who report their age are between 13 and 17.</p>
<p>A lot of other interesting research and analysis has been done on the blogs <a href="http://destinationtoast.tumblr.com/stats">Destination: Toast!</a> and <a href="http://toastystats.tumblr.com/">TOASTYSTATS</a>.</p>
<h2 id="basic-methods">Basic Methods</h2>
<p>In addition to allowing users to post stories they write, fanfiction.net allows authors to “favorite” stories they like. Looking at which stories tend to be favorited by the same users gives us a way to understand connections between stories.</p>
<div class="floatrightimgcontainer">
<img src="img/explanation.png" alt="" style="">
<div class="caption">

</div>
</div>
<div class="spaceafterimg">

</div>
<p>In order to analyze this, we must collect a large amount of metadata from fanfiction.net (“scraping”). We note that we don’t actually collect any significant content, just a lot of data about relationships between pieces of content. Fanfiction.net’s terms of service, as the author understands them, allow this with some restrictions:</p>
<blockquote>
<p>4(E) You agree not to use or launch any automated system, including without limitation, “robots,” “spiders,” or “offline readers,” that accesses the Website in a manner that sends more request messages to the FanFiction.Net servers in a given period of time than a human can reasonably produce in the same period by using a conventional on-line web browser. Notwithstanding the foregoing, FanFiction.Net grants the operators of public search engines permission to use spiders to copy materials from the site for the sole purpose of and solely to the extent necessary for creating publicly available searchable indices of the materials, but not caches or archives of such materials…</p>
</blockquote>
<p>In order to ensure compliance with these terms, the author intentionally built significant rate limiting into the scraper and took care to minimize the load put on fanfiction.net. While the issue of academic analysis was not mentioned, it was not excluded and fanfiction.net’s operators have not previously objected to similar academic work. Further, this work could be the preliminary research needed for someone to build a good fanficiton search engine.</p>
<p>Another section of the terms of service prohibits collecting personally identifiable information, which they define to include usernames. As such, I have deliberately discarded all such information and don’t use it. (Though, I note that several search engines do – try searching for an authors name on any major search engine.) I do refer to some usernames in this post, but that was done entirely by hand.</p>
<p>In collecting data, since we are only looking at a subset of users, it is important to be wary of sampling bias. For example, if we sampled authors starting from the favorites of a particular author, or from those who had contributed stories to a community, we might get a very skewed perspective of the stories on fanfiction.net. The author considered a number of approaches, but concluded the fairest approach would be to use the authors of the most reviewed stories on fanfiction.net. This is a bias, but it should bias us towards the most interesting and important parts of the graph.</p>
<h2 id="graph-construction">Graph Construction</h2>
<p>A <a href="http://en.wikipedia.org/wiki/Graph_(mathematics)">graph</a>, in the context of mathematics, is a collection of objects called vertices joined by connections called edges. For example, cities can be thought of as the vertices a graph connected by different highways and roads (the edges).</p>
<div class="centerimgcontainer">
<img src="img/example-graph.svg" alt="" style="">
<div class="caption">
An example of a graph (from Wikipedia)
</div>
</div>
<div class="spaceafterimg">

</div>
<p>A weighted graph is a graph where some edges are “stronger” than others. For example, some cities are connected by giant 6-lane highways, while others are connected by gravel roads. Larger weights represent stronger connections and smaller weights represent weaker ones. A weight of zero is the same thing as having no connection at all.</p>
<p>We will be interpreting fanfiction as a weighted graph, where edges represent a “connection” between stories. We will be using as our weights for edges the probability that someone will like both stories, given that they like one. That is, <span class="math">\(W_{a, b} = \frac{|F_a \cap F_b|}{|F_a \cup F_b|}\)</span> where <span class="math">\(F_s\)</span> is the users who favorited the story <span class="math">\(s\)</span>.</p>
<p>There are lots of other possibilities, some resulting in directed graphs:</p>
<ul>
<li>(directed) The probability that someone who favorites <span class="math">\(a\)</span> will favorite <span class="math">\(b\)</span>: <span class="math">\(W_{a\to b} = \frac{|F_a \cap F_b|}{|F_a|}\)</span></li>
<li>The probability that someone who favorites <span class="math">\(a\)</span> favorites <span class="math">\(b\)</span> times the probability that someone who favorites <span class="math">\(b\)</span> favorites <span class="math">\(a\)</span>: <span class="math">\(W_{a,b} = \frac{|F_a \cap F_b|^2}{|F_a| * |F_b|}\)</span></li>
<li>The lesser of the probability that someone who favorites <span class="math">\(a\)</span> favorites <span class="math">\(b\)</span> and the probability that someone who favorites <span class="math">\(b\)</span> favorites <span class="math">\(a\)</span>: <span class="math">\(W_{a,b} = \min\left(\frac{|F_a \cap F_b|}{|F_a|}, \frac{|F_a \cap F_b|}{|F_b|} \right)\)</span></li>
</ul>
<p>Our experience was that it didn’t matter too much for the results, for large graphs.</p>
<p>(It’s worth noting that many of these could easily generalize to higher-dimensional edges for a weighted hyper-graph.)</p>
<p>In our selected weight definition, <span class="math">\(W_{a, b} = \frac{|F_a \cap F_b|}{|F_a \cup F_b|}\)</span>, we give equal weight to the preferences of all users. But there’s a lot of variance between users: some favorite everything under the sun, while others very selectively favorite stories they really like. If we give the users who favorite thousands of stories the same weight as users who favorite ten, the users who favorite thousands dominate everything (and aren’t a very good signal).</p>
<p>Instead, we give each user <span class="math">\(u\)</span> a weight of <span class="math">\(\frac{1}{20+n(u)}\)</span> where <span class="math">\(n(u)\)</span> denotes the number of stories <span class="math">\(u\)</span> has favorited. This results in a measure on the space of users, <span class="math">\(\mu(S) = \sum_{u \in S} \frac{1}{20+n(u)}\)</span>, and the equation for our weights becomes <span class="math">\(W_{a, b} = \frac{\mu(F_a \cap F_b)}{\mu(F_a \cup F_b)}\)</span>.</p>
<p>Applying these techniques to a couple of the top Harry Potter stories, we get the following graph (using <a href="http://www.graphviz.org/">graphviz</a>):</p>
<div class="bigcenterimgcontainer">
<img src="img/HP-basic.png" alt="Small labeled graph of top Harry Potter stories" style="">
<div class="caption">
Small labeled graph of top Harry Potter stories
</div>
</div>
<div class="spaceafterimg">

</div>
<p>With a small amount of investigation, it’s easy to understand a lot of the graph’s structure. For example, on the lower right hand side, there’s a triangular clique.</p>
<div class="floatrightimgcontainer">
<img src="img/HP-basic-clique.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>A quick Google search reveals that this triangular clique consists of the “Dark Prince Trilogy” by Kurinoone. The stories are more strongly linked to their immediate predecessor/successor than the pair separated by a story are to eachother.</p>
<h2 id="large-graph-visualizations-for-harry-potter">Large Graph visualizations for Harry Potter</h2>
<p>If we use different tools, we can visualize much larger graphs.</p>
<p>We consider the top 2,000 most reviewed Harry Potter stories and their authors. Based on the author’s favorite lists, we construct a weighted graph, with the stories as nodes (edge weights are calculated as above).</p>
<p>We then prune the graph’s edges, keeping the top 8,000 most strongly weighted edges. We also prune the nodes, keeping only those with at least one edge. This leaves us with a graph of 1,623 nodes and 8,000 edges.</p>
<p>We then load this graph into the graph visualization tool <a href="https://gephi.org/">gephi</a>. We layout the graph using the OpenOrd and ForceAtlas2 layout algorithms. (OpenOrd was particularly good at extracting clusters. Beyond that, this was largely a matter of aesthetic taste.)</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-HP-blank.png" alt="" style="">
<div class="caption">
Graph of Harry Potter Fanfiction (top 1,623 stories)
</div>
</div>
<div class="spaceafterimg">

</div>
<p>We can see lots of interesting structure in this graph: there are lots of clusters, some more connected than others.</p>
<p>A first hypothesis might be that some of these clusters are caused by language. As it turns out, this is the case:</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-HP-lang-labeled.png" alt="" style="">
<div class="caption">
Graph of Harry Potter Fanfiction, colored by language
</div>
</div>
<div class="spaceafterimg">

</div>
<p>Another cause of clusters may be the “ship” (romantic pairing of the story). Many readers have a strong loyalty to a particular ship – for example, they might feel very strongly that Harry and Hermione should be together.</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-HP-ships-labeled.png" alt="" style="">
<div class="caption">
Graph of Harry Potter Fanfiction, colored by ship
</div>
</div>
<div class="spaceafterimg">

</div>
<p>(Note: Ships are inferred from tags story summaries. HP = Harry Potter, HG = Hermione Granger, GW = Ginny Weasley, DM = Draco Malfoy, SS = Severus Snape and LV = Lord Voldemort.)</p>
<p>One interesting point is that by far the most diffused ship is HP/GW. It seems likely that this is because it is the ship we see in cannon Harry Potter, and so many stories not focused on romance default to it and unaligned readers are more tolerant of it.</p>
<p>One striking pattern in fanfiction is that a massive fraction of stories are male/male pairings. Such stories are frequently referred to as “slash.”</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-HP-slash-labeled.png" alt="" style="">
<div class="caption">
Graph of Harry Potter Fanfiction, colored by slash
</div>
</div>
<div class="spaceafterimg">

</div>
<p>Many stories include a slash tag in the summary. Some other stories tag themselves as “no-slash.”</p>
<p>One interesting pattern is that stories tagged “no-slash” concentrate around parts of the border of slash stories. One possible reason may be that authors writing stories that might, from a glance at the summary or characters list, look like slash (for example, a story about Snape mentoring Harry, or Draco and Harry as friends) feel the need to explicitly signal that that is not the topic of their story.</p>
<p>The predisposition of the French cluster towards slash stories is interesting, but the cluster is so small I am hesitant to read anything into it.</p>
<p>You can also explore an <a href="graphs/HP-ship/">interactive graph of Harry Potter fanfiction</a>.</p>
<h2 id="large-graph-visualizations-for-other-fandoms">Large Graph Visualizations for Other Fandoms</h2>
<p>Of course, we can apply the exact same tricks to other fandoms.</p>
<p><strong>Naruto</strong></p>
<p>For example, Naruto is the second biggest fandom. Here’s a graph of it:</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-NAR-blank.png" alt="" style="">
<div class="caption">
Graph of top Naruto fanfiction (1,123 nodes and 4,000 edges)
</div>
</div>
<div class="spaceafterimg">

</div>
<p>We can look at languages again:</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-NAR-lang-labeled.png" alt="" style="">
<div class="caption">
Graph of top Naruto fanfiction, colored by language
</div>
</div>
<div class="spaceafterimg">

</div>
<p>And also for ships:</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-NAR-ships-labeled.png" alt="" style="">
<div class="caption">
Graph of top Naruto fanfiction, colored by ship
</div>
</div>
<div class="spaceafterimg">

</div>
<p><strong>Twilight</strong></p>
<p>And again, we can graph the top twilight stories:</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-TWI-blank.png" alt="" style="">
<div class="caption">
Graph of top Twilight fanfiction (1,031 nodes, 5,00 edges)
</div>
</div>
<div class="spaceafterimg">

</div>
<p>We can color it by language:</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-TWI-lang-labeled.png" alt="" style="">
<div class="caption">
Graph of top Twilight fanfiction, colored by language
</div>
</div>
<div class="spaceafterimg">

</div>
<p>And by ship:</p>
<div class="bigcenterimgcontainer">
<img src="img/graph-TWI-ships-labeled.png" alt="" style="">
<div class="caption">
Graph of top Twilight fanfiction, colored by ship
</div>
</div>
<div class="spaceafterimg">

</div>
<p>One thing that seems pretty surprising, without inside knowledge of the fandom, is the lack of stories where the pairing involves Jacob. On further inspection, we find that there are stories like that on fanfiction.net, but they aren’t amongst the most highly reviewed. Perhaps this pairing prefers other websites? I’d love comments from anyone with insight into this.</p>
<p>You can also explore an <a href="graphs/NAR-ship/">interactive graph of Naruto fanfiction</a> and of <a href="graphs/TWI-ship/">Twilight fanfiction</a>.</p>
<h2 id="pagerank">PageRank</h2>
<p>What are the best fanfics on fanfiction.net? How can we identify them?</p>
<p>A naive approach would be to select the most favorited or reviewed stories. But people’s quality of taste varies. A more sophisticated approach is Google’s PageRank algorithm which is used to determine which web pages are of high quality.</p>
<p>In a normal vote gives equal weight to every voter. But some voters are better qualified to decide than others. In PageRank, we recalculate the votes again and again, giving each “person’s” vote a weight based on how many votes they received in the previous step.</p>
<p>In the case of the Internet, we interpret a website linking to another website as that website voting for the one it links to. Similarly, we can apply it to fanfiction by interpreting story A as “voting” for a story B with a weight of the probability that a user who likes A also likes B.</p>
<p><strong>Harry Potter top stories by PageRank:</strong></p>
<ol>
        <li>
<a href="http://fanfiction.net/s/1260679">Realizations</a> (16.4)
</li>
        <li>
<a href="http://fanfiction.net/s/2636963">Harry Potter and the Nightmares of Futures Past</a> (15.7)
</li>
        <li>
<a href="http://fanfiction.net/s/2318355">Make A Wish</a> (14.0)
</li>
        <li>
<a href="http://fanfiction.net/s/5554780">Poison Pen</a> (11.7)
</li>
        <li>
<a href="http://fanfiction.net/s/6413108">To Shape and Change</a> (11.5)
</li>
        <li>
<a href="pagerank/hp.html"><b>More</b></a>
</ol>



<p><strong>Naruto top stories by PageRank:</strong></p>
<ol>
        <li>
<a href="http://fanfiction.net/s/2731239">Team 8</a> (11.1)
</li>
        <li>
<a href="http://fanfiction.net/s/6694302">Naruto: Myoushuu no Fuuin</a> (6.42)
</li>
        <li>
<a href="http://fanfiction.net/s/5409165">It’s For a Good Cause, I Swear!</a> (5.57)
</li>
        <li>
<a href="http://fanfiction.net/s/6051938">The Sealed Kunai</a> (5.24)
</li>
        <li>
<a href="http://fanfiction.net/s/3929411">Chunin Exam Day</a> (5.14)
</li>
        <li>
<a href="pagerank/naruto.html"><b>More</b></a>
</ol>


<p><strong>Twilight top stories by PageRank:</strong></p>
<ol>
        <li>
<a href="http://fanfiction.net/s/5100876">The Blessing and the Curse</a> (18.6)
</li>
        <li>
<a href="http://fanfiction.net/s/4901517">Tropic of Virgo</a> (15.0)
</li>
        <li>
<a href="http://fanfiction.net/s/5319052">A Rough Start</a> (12.7)
</li>
        <li>
<a href="http://fanfiction.net/s/4769414">Creature of Habit</a> (12.6)
</li>
        <li>
<a href="http://fanfiction.net/s/6550419">The Plan</a> (10.2)
</li>
        <li>
<a href="pagerank/twi.html"><b>More</b></a>
</ol>

<p>One neat thing we can do is give nodes on our graphs a size based on their PageRank. (We can also color nodes based on the first three components of the singular value decomposition of the adjacency matrix.)</p>
<div class="bigcenterimgcontainer">
<img src="img/HP_union_size_larger.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<h2 id="story-recommendation">Story Recommendation</h2>
<p>There’s something that’s just begging to be done, at this point: story recommendations. Given our knowledge of what stories many users like, can we recommend other stories that they’re probable to like?</p>
<p>This problem is called collaborative filtering, and is a well-established area. Unfortunately, it isn’t something I’m terribly knowledgeable about, so I took a relatively naive approach: sum over the preferences of all users, weighted by how similar their preferences are to the user you are trying to predict.</p>
<p>Specifically, we give each story, <span class="math">\(s\)</span>, a rank <span class="math">\(R_u(s)\)</span>, for a user <span class="math">\(u\)</span>. If the rank is high, we think <span class="math">\(u\)</span> is likely to like <span class="math">\(s\)</span>.</p>
<p><span class="math">\[R_u(s) = \sum_{v\in F_s \setminus \{u\}} \left(\frac{|S(u)\cap S(v)|}{20+|S(v)|}\right)^2\]</span></p>
<p>where <span class="math">\(F_s\)</span> is the set of users who favorited <span class="math">\(s\)</span> and <span class="math">\(S(u)\)</span> is the stories favorited by the user <span class="math">\(u\)</span>.</p>
<p>For example, we can make recommendations for S’TarKan, the author of the most favorited Harry Potter story on fanfiction.net:</p>
<ul>
	<li>
*<a href="http://fanfiction.net/s/2559745">Learning to Breathe</a> (1.459)
</li>
	<li>
*<a href="http://fanfiction.net/s/2954601">Taking Control</a> (1.383)
</li>
	<li>
*<a href="http://fanfiction.net/s/1594791">Backwards Compatible</a> (1.381)
</li>
	<li>
*<a href="http://fanfiction.net/s/2636963">Harry Potter and the Nightmares of Futures Past</a> (1.377)
</li>
	<li>
*<a href="http://fanfiction.net/s/2479927">Harry Potter and Fate’s Debt</a> (1.218)
</li>
	<li>
…
</li>
</ul>

<p>A * denotes that this is already one of the users favorite stories or one of their own stories. We can exclude their favorite stories, and their own stories:</p>
<ul>
	<li>
<a href="http://fanfiction.net/s/2318355">Make A Wish</a> (0.949)
</li>
	<li>
<a href="http://fanfiction.net/s/3401052">A Black Comedy</a> (0.750)
</li>
	<li>
<a href="http://fanfiction.net/s/4536005">Oh God Not Again!</a> (0.679)
</li>
	<li>
<a href="http://fanfiction.net/s/1260679">Realizations</a> (0.642)
</li>
	<li>
<a href="http://fanfiction.net/s/2107570">Lord of Caer Azkaban</a> (0.635)
</li>
	<li>
…
</li>
</ul>

<p>These are all very popular stories. It’s not very useful to S’TarKan if we recommend them extremely popular stories that they’ve almost certainly seen before. As such, it is interesting to penalize the popularity of stories.</p>
<p>Consider <span class="math">\(\frac{R_u(s)}{|F_s|^k}\)</span>. When <span class="math">\(k = 0\)</span>, it’s our original rank. When <span class="math">\(k = 1\)</span>, it full normalizes stories against popularity. And in between, it penalizes popularity to varying degrees. If we set k = 0.7, we get these recommendations:</p>
<ul>
	<li>
<a href="http://fanfiction.net/s/2114122">Insanity</a> (0.034)
</li>
	<li>
<a href="http://fanfiction.net/s/1995612">Shadow of the Serpent</a> (0.032)
</li>
	<li>
<a href="http://fanfiction.net/s/2160456">The Bargain</a> (0.031)
</li>
	<li>
<a href="http://fanfiction.net/s/1975479">Sinners</a> (0.029)
</li>
	<li>
<a href="http://fanfiction.net/s/926568">Harry Potter and the Order of the Phoenix</a> (0.029)
</li>
	<li>
…
</li>
</ul>

<p>You can think of these as stories that are <em>unexpectedly</em> popular amongst similar users. Similar users like them a lot more than random users like them. (Though, perhaps 0.7 is a bit too extreme.)</p>
<p>Curious about what this algorithm would recommend for you? If you’re a popular fanfiction author, you may be in my recommendations for top users for <a href="recs/hp.html">Harry Potter</a>, <a href="recs/nar.html">Naruto</a> or <a href="recs/twi.html">Twilight</a>.</p>
<p>Since my scripts can’t look at your author name while complying with fanfiction.net’s terms of service, you will need to know your <em>author ID</em>. To get it, go to your fanfiction.net profile page and look at the URL. It will be of the form: <code>http://fanfiction.net/u/author_ID/...</code>. Then search for your author ID in the file!</p>
<p>I’m certain one could do much better if they wanted to put a bit more effort into it. :)</p>
<h2 id="conclusion">Conclusion</h2>
<p>In light of all this, I’d like to reflect on a few things.</p>
<p><strong>Big Data</strong>: A year ago, I was very dismissive of “big data” as a buzzword. Primarily, it seems to be thrown around by business people who don’t really understand much. But one thing I’ve learned in explorations of data like this one and working in machine learning, is that there is something very powerful about larger amounts of data. There’s something very qualitatively different. The fanfiction data I used was actually quite small, only a few hundred users, because of how I limited the amount I downloaded, but I think it still demonstrates the sorts of things that become possible as you have larger amounts of data. (To be honest, a much more compelling example is the progress that’s been made in computer vision using ImageNet… But this still influenced my views.)</p>
<p><strong>Digital Humanities</strong>: Digital humanities also seems to be a bit of a buzzword. But I hope this provides a simple example of the power that can come from applying a little bit of math and computer science to humanities problems.</p>
<p><strong>Metadata and Privacy</strong>: In this essay, we analyzed stories by looking at whether they were favorited by the same users. There’s a natural “dual” to this: analyzing users by looking at whether they favorited the same stories. This would give us a graph of connections between users and allow us to find clusters of users. But what if you use other forms of metadata? For example, we now know that the US government has metadata on who phones who. It seems very likely that many companies and governments have information on where your cellphone is as a function of time. All this can construct a graph of society. I can’t really fathom how much one must be able to learn about someone from that. (And how easy it would be to misinterpret.)</p>
<p><strong>Fanfiction Websites</strong>: I think there’s a lot of potential for fanfiction websites to better serve their users based on the techniques outlined here. I’d be really thrilled to see fanfiction.net or Archive Of Our Own adopt some of these ideas. Imagine being able to list a handful of stories in some category you’re interested in and discover others? Or get good recommendations? The ideas are all pretty straightforward once you think of them. I’d be very happy to talk to the groups behind different fanfiction websites and provide some help or share example code.</p>
<p><strong>Deep Learning and NLP</strong>: Recently, there’s been some really cool results in applying Deep Learning to Natural Language Processing. One would need a lot more data than I collected, and it would take more effort, but I bet one could do some really interesting things here.</p>
<p><strong>t-SNE</strong>: <a href="http://homepage.tudelft.nl/19j49/t-SNE.html">t-Distributed Stochastic Neighbor Embedding</a>, is an algorithm for visualizing the structure of high-dimensional data. It would be a much simpler approach to understanding the structure of fanfiction than the graph based one I used here, and probably give much better results. If I was starting again, I would use it.</p>
<p><strong>Resources</strong>: In principle, I’d really like to share my code and make it easy for people to replicate the work I described here. However, I think that would be really rude to fanfiction.net because it could result in lots of people scraping their website, and it seems likely many would remove my rate limiter. An alternative would be to share my extracted metadata, but, again, I think it would be really rude to do that without fanfiction.net’s permission, and possibly a violation of their terms of service. So, in the end, I’m not sharing any resources. That said, all of this can be done pretty easily.</p>
<p><em>(This post is a fun experiment done primarily for amusement. I would be delighted to hear your comments and thoughts: you can comment inline or at the end. For typos, technical errors, or clarifications you would like to see added, you are encouraged to make a pull request on <a href="https://github.com/colah/Fanfiction-Graphs-Post">github</a>. If you enjoyed this post, you might consider subscribing to my <a href="../../rss.xml">RSS feed</a>.)</em></p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>Thank you to Eliana Lorch, Taren Stinebrickner-Kauffman, Mary Becica, and Jacob Steinhardt for their comments and encouragement.</p>]]></description>
    <pubDate>Sun, 06 Jul 2014 00:00:00 UT</pubDate>
    <guid>http://colah.github.io/posts/2014-07-FFN-Graphs-Vis/</guid>
</item>
<item>
    <title>Neural Networks, Manifolds, and Topology</title>
    <link>http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/</link>
    <description><![CDATA[<p>Recently, there’s been a great deal of excitement and interest in deep neural networks because they’ve achieved breakthrough results in areas such as computer vision.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>However, there remain a number of concerns about them. One is that it can be quite challenging to understand <em>what</em> a neural network is really doing. If one trains it well, it achieves high quality results, but it is challenging to understand how it is doing so. If the network fails, it is hard to understand what went wrong.</p>
<p>While it is challenging to understand the behavior of deep neural networks in general, it turns out to be much easier to explore low-dimensional deep neural networks – networks that only have a few neurons in each layer. In fact, we can create visualizations to completely understand the behavior and training of such networks. This perspective will allow us to gain deeper intuition about the behavior of neural networks and observe a connection linking neural networks to an area of mathematics called topology.</p>
<p>A number of interesting things follow from this, including fundamental lower-bounds on the complexity of a neural network capable of classifying certain datasets.</p>
<h2 id="a-simple-example">A Simple Example</h2>
<p>Let’s begin with a very simple dataset, two curves on a plane. The network will learn to classify points as belonging to one or the other.</p>
<div class="centerimgcontainer">
<img src="img/simple2_data.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>The obvious way to visualize the behavior of a neural network – or any classification algorithm, for that matter – is to simply look at how it classifies every possible data point.</p>
<p>We’ll start with the simplest possible class of neural network, one with only an input layer and an output layer. Such a network simply tries to separate the two classes of data by dividing them with a line.</p>
<div class="centerimgcontainer">
<img src="img/simple2_linear.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>That sort of network isn’t very interesting. Modern neural networks generally have multiple layers between their input and output, called “hidden” layers. At the very least, they have one.</p>
<div class="centerimgcontainer">
<img src="img/example_network.svg" alt="" style="">
<div class="caption">
Diagram of a simple network from Wikipedia
</div>
</div>
<div class="spaceafterimg">

</div>
<p>As before, we can visualize the behavior of this network by looking at what it does to different points in its domain. It separates the data with a more complicated curve than a line.</p>
<div class="centerimgcontainer">
<img src="img/simple2_0.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>With each layer, the network transforms the data, creating a new <em>representation</em>.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> We can look at the data in each of these representations and how the network classifies them. When we get to the final representation, the network will just draw a line through the data (or, in higher dimensions, a hyperplane).</p>
<p>In the previous visualization, we looked at the data in its “raw” representation. You can think of that as us looking at the input layer. Now we will look at it after it is transformed by the first layer. You can think of this as us looking at the hidden layer.</p>
<p>Each dimension corresponds to the firing of a neuron in the layer.</p>
<div class="centerimgcontainer">
<img src="img/simple2_1.png" alt="" style="">
<div class="caption">
The hidden layer learns a representation so that the data is linearly seperable
</div>
</div>
<div class="spaceafterimg">

</div>
<h2 id="continuous-visualization-of-layers">Continuous Visualization of Layers</h2>
<p>In the approach outlined in the previous section, we learn to understand networks by looking at the representation corresponding to each layer. This gives us a discrete list of representations.</p>
<p>The tricky part is in understanding how we go from one to another. Thankfully, neural network layers have nice properties that make this very easy.</p>
<p>There are a variety of different kinds of layers used in neural networks. We will talk about tanh layers for a concrete example. A tanh layer <span class="math">\(\tanh(Wx+b)\)</span> consists of:</p>
<ol type="1">
<li>A linear transformation by the “weight” matrix <span class="math">\(W\)</span></li>
<li>A translation by the vector <span class="math">\(b\)</span></li>
<li>Point-wise application of tanh.</li>
</ol>
<p>We can visualize this as a continuous transformation, as follows:</p>
<div class="centerimgcontainer">
<img src="img/1layer.gif" alt="Gradually applying a neural network layer" style="">
</div>
<div class="spaceafterimg">

</div>
<p>The story is much the same for other standard layers, consisting of an affine transformation followed by pointwise application of a monotone activation function.</p>
<p>We can apply this technique to understand more complicated networks. For example, the following network classifies two spirals that are slightly entangled, using four hidden layers. Over time, we can see it shift from the “raw” representation to higher level ones it has learned in order to classify the data. While the spirals are originally entangled, by the end they are linearly separable.</p>
<div class="centerimgcontainer">
<img src="img/spiral.1-2.2-2-2-2-2-2.gif" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>On the other hand, the following network, also using multiple layers, fails to classify two spirals that are more entangled.</p>
<div class="centerimgcontainer">
<img src="img/spiral.2.2-2-2-2-2-2-2.gif" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>It is worth explicitly noting here that these tasks are only somewhat challenging because we are using low-dimensional neural networks. If we were using wider networks, all this would be quite easy.</p>
<p><em>(Andrej Karpathy has made a <a href="http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html">nice demo</a> based on ConvnetJS that allows you to interactively explore networks with this sort of visualization of training!)</em></p>
<h2 id="topology-of-tanh-layers">Topology of tanh Layers</h2>
<p>Each layer stretches and squishes space, but it never cuts, breaks, or folds it. Intuitively, we can see that it preserves topological properties. For example, a set will be connected afterwards if it was before (and vice versa).</p>
<p>Transformations like this, which don’t affect topology, are called homeomorphisms. Formally, they are bijections that are continuous functions both ways.</p>
<p><strong>Theorem</strong>: Layers with <span class="math">\(N\)</span> inputs and <span class="math">\(N\)</span> outputs are homeomorphisms, if the weight matrix, <span class="math">\(W\)</span>, is non-singular. (Though one needs to be careful about domain and range.)</p>
<p><strong>Proof</strong>: Let’s consider this step by step:</p>
<ol type="1">
<li>Let’s assume <span class="math">\(W\)</span> has a non-zero determinant. Then it is a bijective linear function with a linear inverse. Linear functions are continuous. So, multiplying by <span class="math">\(W\)</span> is a homeomorphism.</li>
<li>Translations are homeomorphisms</li>
<li>tanh (and sigmoid and softplus but not ReLU) are continuous functions with continuous inverses. They are bijections if we are careful about the domain and range we consider. Applying them pointwise is a homemorphism</li>
</ol>
<p>Thus, if <span class="math">\(W\)</span> has a non-zero determinant, our layer is a homeomorphism. ∎</p>
<p>This result continues to hold if we compose arbitrarily many of these layers together.</p>
<h2 id="topology-and-classification">Topology and Classification</h2>
<div class="floatrightimgcontainer">
<img src="img/topology_base.png" alt="" style="">
<div class="caption">
<span class="math">\(A\)</span> is red, <span class="math">\(B\)</span> is blue
</div>
</div>
<div class="spaceafterimg">

</div>
<p>Consider a two dimensional dataset with two classes <span class="math">\(A, B \subset \mathbb{R}^2\)</span>:</p>
<p><span class="math">\[A = \{x | d(x,0) &lt; 1/3\}\]</span></p>
<p><span class="math">\[B = \{x | 2/3 &lt; d(x,0) &lt; 1\}\]</span></p>
<p><strong>Claim</strong>: It is impossible for a neural network to classify this dataset without having a layer that has 3 or more hidden units, regardless of depth.</p>
<p>As mentioned previously, classification with a sigmoid unit or a softmax layer is equivalent to trying to find a hyperplane (or in this case a line) that separates <span class="math">\(A\)</span> and <span class="math">\(B\)</span> in the final represenation. With only two hidden units, a network is topologically incapable of separating the data in this way, and doomed to failure on this dataset.</p>
<p>In the following visualization, we observe a hidden representation while a network trains, along with the classification line. As we watch, it struggles and flounders trying to learn a way to do this.</p>
<div class="centerimgcontainer">
<img src="img/topology_2D-2D_train.gif" alt="" style="">
<div class="caption">
For this network, hard work isn’t enough.
</div>
</div>
<div class="spaceafterimg">

</div>
<p>In the end it gets pulled into a rather unproductive local minimum. Although, it’s actually able to achieve <span class="math">\(\sim 80\%\)</span> classification accuracy.</p>
<p>This example only had one hidden layer, but it would fail regardless.</p>
<p><strong>Proof</strong>: Either each layer is a homeomorphism, or the layer’s weight matrix has determinant 0. If it is a homemorphism, <span class="math">\(A\)</span> is still surrounded by <span class="math">\(B\)</span>, and a line can’t separate them. But suppose it has a determinant of 0: then the dataset gets collapsed on some axis. Since we’re dealing with something homeomorphic to the original dataset, <span class="math">\(A\)</span> is surrounded by <span class="math">\(B\)</span>, and collapsing on any axis means we will have some points of <span class="math">\(A\)</span> and <span class="math">\(B\)</span> mix and become impossible to distinguish between. ∎</p>
<p>If we add a third hidden unit, the problem becomes trivial. The neural network learns the following representation:</p>
<div class="centerimgcontainer">
<img src="img/topology_3d.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>With this representation, we can separate the datasets with a hyperplane.</p>
<p>To get a better sense of what’s going on, let’s consider an even simpler dataset that’s 1-dimensional:</p>
<div class="floatrightimgcontainer">
<img src="img/topology_1d.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p><span class="math">\[A = [-\frac{1}{3}, \frac{1}{3}]\]</span></p>
<p><span class="math">\[B = [-1, -\frac{2}{3}] \cup [\frac{2}{3}, 1]\]</span></p>
<p>Without using a layer of two or more hidden units, we can’t classify this dataset. But if we use one with two units, we learn to represent the data as a nice curve that allows us to separate the classes with a line:</p>
<div class="centerimgcontainer">
<img src="img/topology_1D-2D_train.gif" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>What’s happening? One hidden unit learns to fire when <span class="math">\(x &gt; -\frac{1}{2}\)</span> and one learns to fire when <span class="math">\(x &gt; \frac{1}{2}\)</span>. When the first one fires, but not the second, we know that we are in A.</p>
<h2 id="the-manifold-hypothesis">The Manifold Hypothesis</h2>
<p>Is this relevant to real world data sets, like image data? If you take the manifold hypothesis really seriously, I think it bares consideration.</p>
<p>The manifold hypothesis is that natural data forms lower-dimensional manifolds in its embedding space. There are both theoretical<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> and experimental<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> reasons to believe this to be true. If you believe this, then the task of a classification algorithm is fundamentally to separate a bunch of tangled manifolds.</p>
<p>In the previous examples, one class completely surrounded another. However, it doesn’t seem very likely that the dog image manifold is completely surrounded by the cat image manifold. But there are other, more plausible topological situations that could still pose an issue, as we will see in the next section.</p>
<h2 id="links-and-homotopy">Links And Homotopy</h2>
<p>Another interesting dataset to consider is two linked tori, <span class="math">\(A\)</span> and <span class="math">\(B\)</span>.</p>
<div class="centerimgcontainer">
<img src="img/link.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>Much like the previous datasets we considered, this dataset can’t be separated without using <span class="math">\(n+1\)</span> dimensions, namely a <span class="math">\(4\)</span>th dimension.</p>
<p>Links are studied in knot theory, an area of topology. Sometimes when we see a link, it isn’t immediately obvious whether it’s an unlink (a bunch of things that are tangled together, but can be separated by continuous deformation) or not.</p>
<div class="bigcenterimgcontainer">
<img src="img/unlink-2spiral.png" alt="" style="">
<div class="caption">
A relatively simple unlink.
</div>
</div>
<div class="spaceafterimg">

</div>
<p>If a neural network using layers with only 3 units can classify it, then it is an unlink. (Question: Can all unlinks be classified by a network with only 3 units, theoretically?)</p>
<p>From this knot perspective, our continuous visualization of the representations produced by a neural network isn’t just a nice animation, it’s a procedure for untangling links. In topology, we would call it an <em>ambient isotopy</em> between the original link and the separated ones.</p>
<p>Formally, an ambient isotopy between manifolds <span class="math">\(A\)</span> and <span class="math">\(B\)</span> is a continuous function <span class="math">\(F: [0,1] \times X \to Y\)</span> such that each <span class="math">\(F_t\)</span> is a homeomorphism from <span class="math">\(X\)</span> to its range, <span class="math">\(F_0\)</span> is the identity function, and <span class="math">\(F_1\)</span> maps <span class="math">\(A\)</span> to <span class="math">\(B\)</span>. That is, <span class="math">\(F_t\)</span> continuously transitions from mapping <span class="math">\(A\)</span> to itself to mapping <span class="math">\(A\)</span> to <span class="math">\(B\)</span>.</p>
<p><strong>Theorem</strong>: There is an ambient isotopy between the input and a network layer’s representation if: a) <span class="math">\(W\)</span> isn’t singular, b) we are willing to permute the neurons in the hidden layer, and c) there is more than 1 hidden unit.</p>
<p><strong>Proof</strong>: Again, we consider each stage of the network individually:</p>
<ol type="1">
<li>The hardest part is the linear transformation. In order for this to be possible, we need <span class="math">\(W\)</span> to have a positive determinant. Our premise is that it isn’t zero, and we can flip the sign if it is negative by switching two of the hidden neurons, and so we can guarantee the determinant is positive. The space of positive determinant matrices is <a href="http://en.wikipedia.org/wiki/Connected_space#Path_connectedness">path-connected</a>, so there exists <span class="math">\(p: [0,1] \to GL_n(\mathbb{R})\)</span><a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> such that <span class="math">\(p(0) = Id\)</span> and <span class="math">\(p(1) = W\)</span>. We can continually transition from the identity function to the <span class="math">\(W\)</span> transformation with the function <span class="math">\(x \to p(t)x\)</span>, multiplying <span class="math">\(x\)</span> at each point in time <span class="math">\(t\)</span> by the continuously transitioning matrix <span class="math">\(p(t)\)</span>.</li>
</ol>
<ol start="2" type="1">
<li>We can continually transition from the identity function to the <span class="math">\(b\)</span> translation with the function <span class="math">\(x \to x + tb\)</span>.</li>
<li>We can continually transition from the identity function to the pointwise use of σ with the function: <span class="math">\(x \to (1-t)x + tσ(x)\)</span>. ∎</li>
</ol>
<p>I imagine there is probably interest in programs automatically discovering such ambient isotopies and automatically proving the equivalence of certain links, or that certain links are separable. It would be interesting to know if neural networks can beat whatever the state of the art is there.</p>
<p><em>(Apparently determining if knots are trivial is NP. This doesn’t bode well for neural networks.)</em></p>
<p>The sort of links we’ve talked about so far don’t seem likely to turn up in real world data, but there are higher dimensional generalizations. It seems plausible such things could exist in real world data.</p>
<p>Links and knots are <span class="math">\(1\)</span>-dimensional manifolds, but we need 4 dimensions to be able to untangle all of them. Similarly, one can need yet higher dimensional space to be able to unknot <span class="math">\(n\)</span>-dimensional manifolds. All <span class="math">\(n\)</span>-dimensional manifolds can be untangled in <span class="math">\(2n+2\)</span> dimensions.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></p>
<p><em>(I know very little about knot theory and really need to learn more about what’s known regarding dimensionality and links. If we know a manifold can be embedded in n-dimensional space, instead of the dimensionality of the manifold, what limit do we have?)</em></p>
<h2 id="the-easy-way-out">The Easy Way Out</h2>
<p>The natural thing for a neural net to do, the very easy route, is to try and pull the manifolds apart naively and stretch the parts that are tangled as thin as possible. While this won’t be anywhere close to a genuine solution, it can achieve relatively high classification accuracy and be a tempting local minimum.</p>
<div class="bigcenterimgcontainer">
<img src="img/tangle.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>It would present itself as very high derivatives on the regions it is trying to stretch, and sharp near-discontinuities. We know these things happen.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> Contractive penalties, penalizing the derivatives of the layers at data points, are the natural way to fight this.<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p>
<p>Since these sort of local minima are absolutely useless from the perspective of trying to solve topological problems, topological problems may provide a nice motivation to explore fighting these issues.</p>
<p>On the other hand, if we only care about achieving good classification results, it seems like we might not care. If a tiny bit of the data manifold is snagged on another manifold, is that a problem for us? It seems like we should be able to get arbitrarily good classification results despite this issue.</p>
<p><em>(My intuition is that trying to cheat the problem like this is a bad idea: it’s hard to imagine that it won’t be a dead end. In particular, in an optimization problem where local minima are a big problem, picking an architecture that can’t genuinely solve the problem seems like a recipe for bad performance.)</em></p>
<h2 id="better-layers-for-manipulating-manifolds">Better Layers for Manipulating Manifolds?</h2>
<p>The more I think about standard neural network layers – that is, with an affine transformation followed by a point-wise activation function – the more disenchanted I feel. It’s hard to imagine that these are really very good for manipulating manifolds.</p>
<p>Perhaps it might make sense to have a very different kind of layer that we can use in composition with more traditional ones?</p>
<p>The thing that feels natural to me is to learn a vector field with the direction we want to shift the manifold:</p>
<div class="centerimgcontainer">
<img src="img/grid_vec.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>And then deform space based on it:</p>
<div class="centerimgcontainer">
<img src="img/grid_bubble.png" alt="" style="">
</div>
<div class="spaceafterimg">

</div>
<p>One could learn the vector field at fixed points (just take some fixed points from the training set to use as anchors) and interpolate in some manner. The vector field above is of the form:</p>
<p><span class="math">\[F(x) = \frac{v_0f_0(x) + v_1f_1(x)}{1+f_0(x)+f_1(x)}\]</span></p>
<p>Where <span class="math">\(v_0\)</span> and <span class="math">\(v_1\)</span> are vectors and <span class="math">\(f_0(x)\)</span> and <span class="math">\(f_1(x)\)</span> are n-dimensional gaussians. This is inspired a bit by <a href="http://en.wikipedia.org/wiki/Radial_basis_function">radial basis functions</a>.</p>
<h2 id="k-nearest-neighbor-layers">K-Nearest Neighbor Layers</h2>
<p>I’ve also begun to think that linear separability may be a huge, and possibly unreasonable, amount to demand of a neural network. In some ways, it feels like the natural thing to do would be to use <a href="knn">k-nearest neighbors</a> (k-NN). However, k-NN’s success is greatly dependent on the representation it classifies data from, so one needs a good representation before k-NN can work well.</p>
<p>As a first experiment, I trained some MNIST networks (two-layer convolutional nets, no dropout) that achieved <span class="math">\(\sim 1\%\)</span> test error. I then dropped the final softmax layer and used the k-NN algorithm. I was able to consistently achieve a reduction in test error of 0.1-0.2%.</p>
<p>Still, this doesn’t quite feel like the right thing. The network is still trying to do linear classification, but since we use k-NN at test time, it’s able to recover a bit from mistakes it made.</p>
<p>k-NN is differentiable with respect to the representation it’s acting on, because of the 1/distance weighting. As such, we can train a network directly for k-NN classification. This can be thought of as a kind of “nearest neighbor” layer that acts as an alternative to softmax.</p>
<p>We don’t want to feedforward our entire training set for each mini-batch because that would be very computationally expensive. I think a nice approach is to classify each element of the mini-batch based on the classes of other elements of the mini-batch, giving each one a weight of 1/(distance from classification target).<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a></p>
<p>Sadly, even with sophisticated architecture, using k-NN only gets down to 5-4% test error – and using simpler architectures gets worse results. However, I’ve put very little effort into playing with hyper-parameters.</p>
<p>Still, I really aesthetically like this approach, because it seems like what we’re “asking” the network to do is much more reasonable. We want points of the same manifold to be closer than points of others, as opposed to the manifolds being separable by a hyperplane. This should correspond to inflating the space between manifolds for different categories and contracting the individual manifolds. It feels like simplification.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Topological properties of data, such as links, may make it impossible to linearly separate classes using low-dimensional networks, regardless of depth. Even in cases where it is technically possible, such as spirals, it can be very challenging to do so.</p>
<p>To accurately classify data with neural networks, wide layers are sometimes necessary. Further, traditional neural network layers do not seem to be very good at representing important manipulations of manifolds; even if we were to cleverly set weights by hand, it would be challenging to compactly represent the transformations we want. New layers, specifically motivated by the manifold perspective of machine learning, may be useful supplements.</p>
<p><em>(This is a developing research project. It’s posted as an experiment in doing research openly. I would be delighted to have your feedback on these ideas: you can comment inline or at the end. For typos, technical errors, or clarifications you would like to see added, you are encouraged to make a pull request <a href="https://github.com/colah/NN-Topology-Post">on github</a>.)</em></p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>Thank you to Yoshua Bengio, Michael Nielsen, Dario Amodei, Eliana Lorch, Jacob Steinhardt, and Tamsyn Waterhouse for their comments and encouragement.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>This seems to have really kicked off with <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizhevsky <em>et al.</em>, (2012)</a>, who put together a lot of different pieces to achieve outstanding results. Since then there’s been a lot of other exciting work.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>These representations, hopefully, make the data “nicer” for the network to classify. There has been a lot of work exploring representations recently. Perhaps the most fascinating has been in Natural Language Processing: the representations we learn of words, called word embeddings, have interesting properties. See <a href="http://research.microsoft.com/pubs/189726/rvecs.pdf">Mikolov <em>et al.</em> (2013)</a>, <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/turian-wordrepresentations-acl10.pdf">Turian <em>et al.</em> (2010)</a>, and, <a href="http://www.socher.org/">Richard Socher’s work</a>. To give you a quick flavor, there is a <a href="http://metaoptimize.s3.amazonaws.com/cw-embeddings-ACL2010/embeddings-mostcommon.EMBEDDING_SIZE=50.png">very nice visualization</a> associated with the Turian paper.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>A lot of the natural transformations you might want to perform on an image, like translating or scaling an object in it, or changing the lighting, would form continuous curves in image space if you performed them continuously.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p><a href="http://comptop.stanford.edu/u/preprints/mumford.pdf">Carlsson <em>et al.</em></a> found that local patches of images form a klein bottle.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p><span class="math">\(GL_n(\mathbb{R})\)</span> is the set of invertible <span class="math">\(n \times n\)</span> matrices on the reals, formally called the <a href="http://en.wikipedia.org/wiki/General_linear_group">general linear group</a> of degree <span class="math">\(n\)</span>.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>This result is mentioned in <a href="http://en.wikipedia.org/wiki/Whitney_embedding_theorem#Isotopy_versions">Wikipedia’s subsection on Isotopy versions</a>.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>See <a href="http://cs.nyu.edu/~zaremba/docs/understanding.pdf">Szegedy <em>et al.</em></a>, where they are able to modify data samples and find slight modifications that cause some of the best image classification neural networks to misclasify the data. It’s quite troubling.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Contractive penalties were introduced in contractive autoencoders. See <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/ICML2011_explicit_invariance.pdf">Rifai <em>et al.</em> (2011)</a>.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>I used a slightly less elegant, but roughly equivalent algorithm because it was more practical to implement in Theano: feedforward two different batches at the same time, and classify them based on each other.<a href="#fnref9">↩</a></p></li>
</ol>
</section>]]></description>
    <pubDate>Sun, 06 Apr 2014 00:00:00 UT</pubDate>
    <guid>http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/</guid>
</item>

    </channel> 
</rss>
